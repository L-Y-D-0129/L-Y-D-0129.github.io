<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>刘煜鼎de学习日记</title>
        <link>https://L-Y-D-0129.github.io/</link>
        <description>Recent content on 刘煜鼎de学习日记</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>刘煜鼎</copyright>
        <lastBuildDate>Sun, 21 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://L-Y-D-0129.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Redis</title>
        <link>https://L-Y-D-0129.github.io/p/redis/</link>
        <pubDate>Sun, 21 Jan 2024 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/p/redis/</guid>
        <description>&lt;img src="https://L-Y-D-0129.github.io/p/redis/2109242356423Y8-0-lp.jpg" alt="Featured image of post Redis" /&gt;&lt;h1 id=&#34;前言&#34;&gt;前言
&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Hello，各位好，我是刘煜鼎！&lt;/p&gt;
&lt;p&gt;这篇文档集合了一些Redis知识&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;主要为数据结构、持久化、集群、缓存等相关知识。&lt;/p&gt;
&lt;h1 id=&#34;redis常见数据类型和应用场景&#34;&gt;Redis常见数据类型和应用场景
&lt;/h1&gt;&lt;p&gt;Redis中常见的数据类型有五种：&lt;strong&gt;String（字符串），Hash（哈希），List（列表），Set（集合），Zset（有序集合）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;随着Redis版本的更新，后面又支持了四种数据类型：&lt;strong&gt;BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;string&#34;&gt;String
&lt;/h2&gt;&lt;h3 id=&#34;介绍&#34;&gt;介绍
&lt;/h3&gt;&lt;p&gt;String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串，也可以是数字(整数或浮点数)，value 最多可以容纳的数据长度是512M。&lt;/p&gt;
&lt;h3 id=&#34;内部实现&#34;&gt;内部实现
&lt;/h3&gt;&lt;p&gt;String类型的底层的数据结构实现主要是int和SDS（简单动态字符串）。&lt;/p&gt;
&lt;p&gt;SDS相比于C的原生字符串：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**SDS 不仅可以保存文本数据，还可以保存二进制数据。**因为SDS使用 len 属性的值而不是空字符来判断字符串是否结束，并且 SDS 的所有 API 都会以处理二进制的方式来处理 SDS 存放在 buf[]数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。&lt;/li&gt;
&lt;li&gt;**SDS 获取字符串长度的时间复杂度是 O(1)。**因为C语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n);而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。&lt;/li&gt;
&lt;li&gt;Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。因为 SDS 在拼接字符串之前会检查SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;字符串的内部编码（encoding）有三种：int、raw和embstr（raw和embstr为SDS（简单动态字符串））。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果一个字符串对象保存的是整数值，并且这个整数值可以用 long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面(将 void*转换成 long)，并将字符串对象的编码设置为int 。&lt;/p&gt;
&lt;p&gt;如果字符串对象保存的是一个字符串则有两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;字符串长度小于等于32字节（redis2.+版本）
字符串对象将使用一个简单动态字符串(SDS)来保存这个字符串，并将对象的编码设置为 embstr，embstr 编码是专门用于保存短字符串的一种优化编码方式。&lt;/li&gt;
&lt;li&gt;字符串长度大于32字节（redis2.+版本）
那么字符串对象将使用一个简单动态字符串(SDS)来保存这个字符串，并将对象的编码设置为 raw。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;可以看到 embstr 和 raw 编码都会使用 SDS 来保存值，但&lt;strong&gt;不同之处在于&lt;/strong&gt; embstr 会通过&lt;strong&gt;一次内存分配&lt;/strong&gt;函数来分配一块连续的内存空间来保存 redisobiect 和 SDS ，而 raw 编码会通过调用&lt;strong&gt;两次内存分配&lt;/strong&gt;函数来分别分配两块空间来保存 redisobject 和 SDS 。Redis这样做会有很多好处:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;embstr 编码将创建字符串对象所需的内存分配次数从 raw编码的两次降低为一次;&lt;/li&gt;
&lt;li&gt;释放 embstr 编码的字符串对象同样只需要调用一次内存释放函数;&lt;/li&gt;
&lt;li&gt;因为 embstr 编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是 embstr 也有缺点的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，所以&lt;strong&gt;embstr编码的字符串对象实际上是只读的&lt;/strong&gt;，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令(例如append)时，程序会先将&lt;strong&gt;对象的编码从embstr转换成raw&lt;/strong&gt;，然后再执行修改命令。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常用操作&#34;&gt;常用操作
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;set：设置字符串&lt;/li&gt;
&lt;li&gt;get：读取字符串&lt;/li&gt;
&lt;li&gt;incr：自增（1）&lt;/li&gt;
&lt;li&gt;decr：自减（1）&lt;/li&gt;
&lt;li&gt;exists：判断某个key是否存在&lt;/li&gt;
&lt;li&gt;strlen：返回字符串长度&lt;/li&gt;
&lt;li&gt;del：删除key&lt;/li&gt;
&lt;li&gt;expire：设置过期时间&lt;/li&gt;
&lt;li&gt;ttl：查看剩余过期时间&lt;/li&gt;
&lt;li&gt;set nx：不存在就插入（成功返回1，失败返回0）&lt;/li&gt;
&lt;li&gt;mset：批量设置字符串&lt;/li&gt;
&lt;li&gt;mget：批量读取字符串&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景&#34;&gt;应用场景
&lt;/h3&gt;&lt;h4 id=&#34;缓存对象&#34;&gt;缓存对象
&lt;/h4&gt;&lt;p&gt;使用 String 来缓存对象有两种方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;直接缓存整个对象的JSON，命令例子:SET user:1&amp;rsquo;{&amp;ldquo;name&amp;rdquo;:&amp;ldquo;隔壁老王&amp;rdquo;，“age”:38}&#39;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;采用将 key 进行分离为 user:ID:属性，采用 MSET存储，用 MGET获取各属性值，&lt;/p&gt;
&lt;p&gt;命令例子:&lt;/p&gt;
&lt;p&gt;MSET  user:1:name &amp;ldquo;隔壁老王头&amp;rdquo; user:1:age 38&lt;/p&gt;
&lt;p&gt;​			 user:2:name &amp;ldquo;楼下老吴头&amp;rdquo; user:2:age 40&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;常规计数&#34;&gt;常规计数
&lt;/h4&gt;&lt;p&gt;因为 Redis 处理命令是单线程，所以执行命令的过程是原子的。因此 String 数据类型适合计数场景，比如计算访问次数、点赞、转发、库存数量等等。&lt;/p&gt;
&lt;h4 id=&#34;分布式锁&#34;&gt;分布式锁
&lt;/h4&gt;&lt;p&gt;SET 命令有个 NX 参数可以实现「key不存在才插入」，可以用它来实现分布式锁&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果 key 不存在，则显示插入成功，可以用来表示加锁成功;&lt;/li&gt;
&lt;li&gt;如果 key 存在，则会显示插入失败，可以用来表示加锁失败。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;共享session信息&#34;&gt;共享session信息
&lt;/h4&gt;&lt;p&gt;通常我们在开发后台管理系统时，会使用 Session 来保存用户的会话(登录)状态，这些 Session 信息会被保存在服务器端，但这只适用于单系统应用，如果是分布式系统此模式将不再适用。&lt;/p&gt;
&lt;p&gt;例如用户一的 Session 信息被存储在服务器一，但第二次访问时用户一被分配到服务器二，这个时候服务器并没有用户一的 Session 信息，就会出现需要重复登录的问题，问题在于分布式系统每次会把请求随机分配到不同的服务器。&lt;/p&gt;
&lt;p&gt;因此，我们需要借助 Redis 对这些 Session 信息进行统一的存储和管理，这样无论请求发送到那台服务器，服务器都会去同一个 Redis 获取相关的 Session 信息，这样就解决了分布式系统下 Session 存储的问题。&lt;/p&gt;
&lt;h2 id=&#34;list&#34;&gt;List
&lt;/h2&gt;&lt;h3 id=&#34;介绍-1&#34;&gt;介绍
&lt;/h3&gt;&lt;p&gt;List列表是最简单的字符串列表，按照插入顺序排序，可以从头部或尾部向List列表添加元素。&lt;/p&gt;
&lt;p&gt;列表的最大长度为2^32 - 1，即每个列表支持超过40亿个元素。&lt;/p&gt;
&lt;h3 id=&#34;内部实现-1&#34;&gt;内部实现
&lt;/h3&gt;&lt;p&gt;类型的底层数据结构是由&lt;strong&gt;双向链表或压缩列表&lt;/strong&gt;实现的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果列表的元素个数小于 512个，列表每个元素的值都小于 64 字节，Redis 会使用&lt;strong&gt;压缩列表&lt;/strong&gt;作为List 类型的底层数据结构;&lt;/li&gt;
&lt;li&gt;如果列表的元素不满足上面的条件，Redis 会使用&lt;strong&gt;双向链表&lt;/strong&gt;作为 List 类型的底层数据结构;&lt;/li&gt;
&lt;li&gt;但是&lt;strong&gt;在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由 quicklist （二者结合）实现了，替代了双向链表和压缩列表。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常用操作-1&#34;&gt;常用操作
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;lpush：在list左侧插入一个新元素&lt;/li&gt;
&lt;li&gt;rpush：在list右侧插入一个新元素&lt;/li&gt;
&lt;li&gt;lrange：从list中指定一个范围来提取元素&lt;/li&gt;
&lt;li&gt;lpop：移除并返回列表头元素&lt;/li&gt;
&lt;li&gt;rpop：移除并返回列表尾元素&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景-1&#34;&gt;应用场景
&lt;/h3&gt;&lt;h4 id=&#34;消息队列&#34;&gt;消息队列
&lt;/h4&gt;&lt;p&gt;消息队列在存取消息时，必须要满足三个需求，分别是&lt;strong&gt;消息保序、处理重复的消息和保证消息可靠性&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Redis 的 List 和 Stream 两种数据类型，就可以满足消息队列的这三个需求。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;如何满足消息保序需求？&lt;/p&gt;
&lt;p&gt;List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。&lt;/p&gt;
&lt;p&gt;List 可以使用 LPUSH+RPOP(或者反过来，RPUSH+LPOP)命令实现消息队列。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;生产者使用 LPUSH key value[value&amp;hellip;]将消息插入到队列的头部，如果 key 不存在则会创建一个空的队列再插入消息。&lt;/li&gt;
&lt;li&gt;消费者使用 RPOP key 依次读取队列的消息，先进先出。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;潜在性能风险点：&lt;/p&gt;
&lt;p&gt;在生产者往 List 中写入数据时，List 并不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用 RPOP命令(比如使用一个while(1)循环)。如果有新消息写入，RPOP命令就会返回结果，否则，RPOP命令返回空值，再继续循环，&lt;/p&gt;
&lt;p&gt;所以，即使没有新消息写入List，消费者也要不停地调用 RPOP 命令，这就会导致消费者程序的 &lt;strong&gt;CPU 一直消耗在执行 RPOP 命令上，带来不必要的性能损失。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了解决这个问题，Redis提供了 BRPOP 命令。BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。和消费者程序自己不停地调用RPOP命令相比，这种方式能节省CPU开销。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何处理重复的消息？&lt;/p&gt;
&lt;p&gt;消费者要实现重复消息的判断，需要2个方面的要求:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消息都有一个全局的ID。&lt;/li&gt;
&lt;li&gt;消费者要记录已经处理过的消息的ID。当收到一条消息后，消费者程序就可以对比收到的消息 ID 和记录的已处理过的消息 ID，来判断当前收到的消息有没有经过处理。如果已经处理过，那么，消费者程序就不再进行处理了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是 &lt;strong&gt;List 并不会为每个消息生成 ID 号，所以我们需要自行为每个消息生成一个全局唯一ID&lt;/strong&gt;，生成之后我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何保证消息的可靠性？&lt;/p&gt;
&lt;p&gt;当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从List 中读取消息了。&lt;/p&gt;
&lt;p&gt;为了留存消息，List类型提供了 BRPOPLPUSH 命令，这个命令&lt;strong&gt;的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List(可以叫作备份 List)留存&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。&lt;/p&gt;
&lt;h5 id=&#34;总结&#34;&gt;总结
&lt;/h5&gt;&lt;p&gt;基于 List 类型的消息队列，满足消息队列的三大需求(消息保序、处理重复的消息和保证消息可靠性)。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息保序:使用 LPUSH+RPOP;&lt;/li&gt;
&lt;li&gt;阻塞读取:使用 BRPOP;&lt;/li&gt;
&lt;li&gt;重复消息处理:生产者自行实现全局唯- ID;&lt;/li&gt;
&lt;li&gt;消息的可靠性:使用 BRPOPLPUSH&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;list做消息队列的缺陷&#34;&gt;List做消息队列的缺陷
&lt;/h5&gt;&lt;p&gt;&lt;strong&gt;List 不支持多个消费者消费同一条消息&lt;/strong&gt;，因为一旦消费者拉取一条消息后，这条消息就从 List 中删除了无法被其它消费者再次消费。&lt;/p&gt;
&lt;p&gt;要实现一条消息可以被多个消费者消费，那么就要将多个消费者组成一个消费组，使得多个消费者可以消费同一条消息，但是 &lt;strong&gt;List 类型并不支持消费组的实现&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这就要说起 Redis 从 5.0 版本开始提供的 Stream 数据类型了，Stream 同样能够满足消息队列的三大需求，而且它还支持「消费组」形式的消息读取。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hash&#34;&gt;Hash
&lt;/h2&gt;&lt;h3 id=&#34;介绍-2&#34;&gt;介绍
&lt;/h3&gt;&lt;p&gt;Hash 是一个键值对(key-value)集合，其中 value 的形式如:value=[{field1,value1},&amp;hellip;{fieldN,valueN}]。Hash 特别适合用于存储对象。&lt;/p&gt;
&lt;h3 id=&#34;内部实现-2&#34;&gt;内部实现
&lt;/h3&gt;&lt;p&gt;Hash 类型的底层数据结构是由&lt;strong&gt;压缩列表或哈希表&lt;/strong&gt;实现的:&lt;/p&gt;
&lt;p&gt;如果哈希类型元素个数小于 512 个，所有值小于64 字节的话，Redis 会使用&lt;strong&gt;压缩列表&lt;/strong&gt;作为 Hash 类型的底层数据结构;&lt;/p&gt;
&lt;p&gt;如果哈希类型元素不满足上面条件，Redis 会使用&lt;strong&gt;哈希表&lt;/strong&gt;作为 Hash 类型的 底层数据结构,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;常用操作-2&#34;&gt;常用操作
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;hset key field value:指定一个 key，设置字段名所对应的值&lt;/li&gt;
&lt;li&gt;hget key field:获取指定 key 和字段对应的值(也可以批量添加)，成功返回操作成功的字段数量&lt;/li&gt;
&lt;li&gt;hmset key field value [field value&amp;hellip;]:批量设置某个 key 的字段和对应值，成功返回 OKhmget key filed [filed&amp;hellip;]:批量返回某个 key 中指定的字段和其对应值&lt;/li&gt;
&lt;li&gt;hgetall key:用于返回一个 hash 中全部的字段和值&lt;/li&gt;
&lt;li&gt;hexists key field:是否存在某个字段&lt;/li&gt;
&lt;li&gt;hdel key field:删除 key 中的字段，可以删除所有字段，如果删除所有字段，相当于删除了这个 key&lt;/li&gt;
&lt;li&gt;hincrby key filed n:增减操作，hash 中没有类似 decrby 的命令，如果想要减值就直接用负数&lt;/li&gt;
&lt;li&gt;hkeys key:获取所有的字段值&lt;/li&gt;
&lt;li&gt;hvals key:获取所有的值&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景-2&#34;&gt;应用场景
&lt;/h3&gt;&lt;h4 id=&#34;缓存对象-1&#34;&gt;缓存对象
&lt;/h4&gt;&lt;p&gt;Hash 类型的(key，field， value)的结构与对象的(对象id，属性，值)的结构相似，也可以用来存储对象。&lt;/p&gt;
&lt;p&gt;在介绍 String 类型的应用场景时有所介绍，String +Json也是存储对象的一种方式，那么存储对象时，到底用 String + json 还是用 Hash 呢?&lt;/p&gt;
&lt;p&gt;一般对象用 String +Json 存储，对象中某些频繁变化的属性可以考虑抽出来用 Hash 类型存储。&lt;/p&gt;
&lt;h4 id=&#34;购物车&#34;&gt;购物车
&lt;/h4&gt;&lt;p&gt;以用户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物车的3个要素。&lt;/p&gt;
&lt;p&gt;涉及的命令如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;添加商品:HSET cart:{用户id}{商品id} 1&lt;/li&gt;
&lt;li&gt;添加数量:HINCRBY cart:f用户id}{商品id} 1&lt;/li&gt;
&lt;li&gt;商品总数:HLEN cart:{用户id}&lt;/li&gt;
&lt;li&gt;删除商品:HDEL cart:{用户id}{商品id}&lt;/li&gt;
&lt;li&gt;获取购物车所有商品: HGETALL cart:{用户id}&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当前仅仅是将商品ID存储到了Redis 中，在回显商品具体信息的时候，还需要拿着商品 id 查询一次数据库，获取完整的商品的信息。&lt;/p&gt;
&lt;h2 id=&#34;set&#34;&gt;Set
&lt;/h2&gt;&lt;h3 id=&#34;介绍-3&#34;&gt;介绍
&lt;/h3&gt;&lt;p&gt;Set 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。&lt;/p&gt;
&lt;p&gt;一个集合最多可以存储 2^32-1 个元素。概念和数学中个的集合基本类似，可以交集，并集，差集等等，所以 Set 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。&lt;/p&gt;
&lt;p&gt;Set 类型和 List 类型的区别如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;List 可以存储重复元素，Set 只能存储非重复元素;&lt;/li&gt;
&lt;li&gt;List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;内部实现-3&#34;&gt;内部实现
&lt;/h3&gt;&lt;p&gt;Set 类型的底层数据结构是由&lt;strong&gt;哈希表或整数集合&lt;/strong&gt;实现的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果集合中的元素都是整数且元素个数小于 512个，Redis 会使用&lt;strong&gt;整数集合&lt;/strong&gt;作为 Set 类型的底层数据结构;&lt;/li&gt;
&lt;li&gt;如果集合中的元素不满足上面条件，则 Redis 使用&lt;strong&gt;哈希表&lt;/strong&gt;作为 Set 类型的底层数据结构。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常用操作-3&#34;&gt;常用操作
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;sadd:添加新元素，元素存在则忽略，key不存在则新建&lt;/li&gt;
&lt;li&gt;smembers:列出集合中所有元素&lt;/li&gt;
&lt;li&gt;sismember:判断元素是否在集合中&lt;/li&gt;
&lt;li&gt;scard:返回集合中元素个数&lt;/li&gt;
&lt;li&gt;srem:移除集合中一个或多个元素，如果移除的不存在就不处理&lt;/li&gt;
&lt;li&gt;sinter:对两个集合求交集&lt;/li&gt;
&lt;li&gt;sunion:对两个集合求并集&lt;/li&gt;
&lt;li&gt;sdiff:对两个集合求差集&lt;/li&gt;
&lt;li&gt;setnx:向 Redis 中添加一个 key，只用当 key 不存在的时候才添加并返回 1，存在则不添加返回 0&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景-3&#34;&gt;应用场景
&lt;/h3&gt;&lt;p&gt;集合的主要几个特性，无序、不可重复、支持并交差等操作。&lt;/p&gt;
&lt;p&gt;因此 Set 类型比较适合用来数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、错集和并集等，当我们存储的数据是无序并且需要去重的情况下，比较适合使用集合类型进行存储。&lt;/p&gt;
&lt;p&gt;但是这里有一个潜在的风险。&lt;strong&gt;Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在主从集群中，为了避免主库因为 Set 做聚合计算(交集、差集、并集)时导致主库被阻塞，我们可以选择一个从库完成聚合统计，或者把数据返回给客户端，由客户端来完成聚合统计。&lt;/p&gt;
&lt;h4 id=&#34;点赞&#34;&gt;点赞
&lt;/h4&gt;&lt;p&gt;Set 类型可以保证一个用户只能点一个赞。&lt;/p&gt;
&lt;p&gt;key 是文章id，value 是用户id&lt;/p&gt;
&lt;h4 id=&#34;共同关注&#34;&gt;共同关注
&lt;/h4&gt;&lt;p&gt;Set 类型支持交集运算，所以可以用来计算共同关注的好友、公众号等。&lt;/p&gt;
&lt;p&gt;key 可以是用户id，value 则是已关注的公众号的id。&lt;/p&gt;
&lt;h4 id=&#34;抽奖活动&#34;&gt;抽奖活动
&lt;/h4&gt;&lt;p&gt;存储某活动中中奖的用户名 ，Set 类型因为有去重功能，可以保证同一个用户不会中奖两次。&lt;/p&gt;
&lt;h2 id=&#34;zset&#34;&gt;Zset
&lt;/h2&gt;&lt;h3 id=&#34;介绍-4&#34;&gt;介绍
&lt;/h3&gt;&lt;p&gt;Zset 类型(有序集合类型)相比于 Set 类型多了一个排序属性 score(分值)，对于有序集合 ZSet 来说每个存储元素相当于有两个值组成的，一个是有集合的元素值，一个是排序值。&lt;/p&gt;
&lt;p&gt;有序集合保留了集合不能有重复成员的特性(分值可以重复)，但不同的是，有序集合中的元素可以排序。&lt;/p&gt;
&lt;h3 id=&#34;内部实现-4&#34;&gt;内部实现
&lt;/h3&gt;&lt;p&gt;Zset 类型的底层数据结构是由&lt;strong&gt;压缩列表或跳表&lt;/strong&gt;实现的:&lt;/p&gt;
&lt;p&gt;如果有序集合的元素个数小于 128个，并且每个元素的值小于 64字节时，Redis 会使用&lt;strong&gt;压缩列表&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;作为 Zset 类型的底层数据结构:&lt;/p&gt;
&lt;p&gt;如果有序集合的元素不满足上面的条件，Redis 会使用&lt;strong&gt;跳表&lt;/strong&gt;作为 Zset 类型的底层数据结构;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;常用操作-4&#34;&gt;常用操作
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;zadd:新增一个有序集合，并加入一个元素&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;zrange:列出有序集合中的元素&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;zrem:从有序集合中删除元素&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;zcard:返回有序集合中的数量&lt;/p&gt;
&lt;p&gt;注意：相比于Set类型，Zset类型没有支持差集运算&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用场景-4&#34;&gt;应用场景
&lt;/h3&gt;&lt;p&gt;Zset 类型(Sorted Set，有序集合)可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如说，我们可以根据元素插入 Sorted set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大。&lt;/p&gt;
&lt;p&gt;在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，可以优先考虑使用Sorted Set.&lt;/p&gt;
&lt;h4 id=&#34;排行榜&#34;&gt;排行榜
&lt;/h4&gt;&lt;p&gt;有序集合比较典型的使用场景就是排行榜。例如学生成绩的排名榜、游戏积分排行榜、视频播放排名、电商系统中商品的销量排名等。&lt;/p&gt;
&lt;h4 id=&#34;电话姓名排序&#34;&gt;电话、姓名排序
&lt;/h4&gt;&lt;p&gt;使用有序集合的ZRANGEBYLEX或ZREVRANGEBYLEX可以帮助我们实现电话号码或姓名的排序，我们以(返回指定成员区间内的成员，按 key 正序排列，分数必须相同)为例。ZRANGEBYLEX&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意:不要在分数不一致的 SortSet 集合中去使用 ZRANGEBYLEX和 ZREVRANGEBYLEX 指令，因为获取的结果会不准确。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;redis数据结构&#34;&gt;Redis数据结构
&lt;/h2&gt;&lt;p&gt;这里主要讲解Redis键值对中值的数据类型，也就是数据的保存形式，其底层实现的方式的数据结构。&lt;/p&gt;
&lt;h2 id=&#34;键值对数据库是怎么实现的&#34;&gt;键值对数据库是怎么实现的？
&lt;/h2&gt;&lt;p&gt;Redis 是怎样实现键值对(key-value)数据库的。&lt;/p&gt;
&lt;p&gt;Redis 的键值对中的 key 就是字符串对象，而 &lt;strong&gt;value 可以是字符串对象，也可以是集合数据类型的对象&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如 List 对象、Hash 对象、Set 对象和 Zset 对象。&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; SET name &amp;#34; 隔壁老王&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;OK
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; HSET person name &amp;#34;楼下老吴&amp;#34; age 18
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; RPUSH stu &amp;#34;小帅&amp;#34; &amp;#34;小美&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;(integer) 4
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这些命令代表着:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一条命令:name 是一个&lt;strong&gt;字符串键&lt;/strong&gt;，因为键的&lt;strong&gt;值是一个字符串对象&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;第二条命令:person 是一个&lt;strong&gt;哈希表键&lt;/strong&gt;，因为键的&lt;strong&gt;值是一个包含两个键值对的哈希表对象&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;第三条命令:stu 是一个&lt;strong&gt;列表键&lt;/strong&gt;，因为键的&lt;strong&gt;值是一个包含两个元素的列表对象&lt;/strong&gt;;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些键值对是如何保存在 Redis 中的呢?&lt;/p&gt;
&lt;p&gt;Redis 是使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。&lt;/p&gt;
&lt;p&gt;Redis 的哈希桶是怎么保存键值对数据的呢?&lt;/p&gt;
&lt;p&gt;哈希桶存放的是指向键值对数据的指针(dictEntry&amp;quot;&lt;em&gt;)，这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身而是保存了 void * key 和 void&lt;/em&gt;value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void * value 指针找到。&lt;/p&gt;
&lt;p&gt;Redis 保存键值对所涉及到的数据结构&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://L-Y-D-0129.github.io/image/%e4%bf%9d%e5%ad%98%e9%94%ae%e5%80%bc%e5%af%b9%e6%b6%89%e5%8f%8a%e5%88%b0%e7%9a%84%e6%95%b0%e6%8d%ae%e7%bb%93%e6%9e%84.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针;&lt;/li&gt;
&lt;li&gt;dict 结构，结构体里存放了2个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash的时候才用;&lt;/li&gt;
&lt;li&gt;ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构(dictEntry)的指针;&lt;/li&gt;
&lt;li&gt;dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void&lt;em&gt;key 和 void&lt;/em&gt;value 指针， &lt;strong&gt;key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash对象、Set 对象和 Zset 对象&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特别说明下，void&lt;em&gt;key 和 void&lt;/em&gt;value 指针指向的是 &lt;strong&gt;Redis 对象&lt;/strong&gt;，Redis 中的每个对象都由 redisObject结构表示。&lt;/p&gt;
&lt;p&gt;对象结构里包含的成员变量:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;type，标识该对象是什么类型的对象(String 对象、 List 对象、Hash 对象、Set对象和 Zset 对象);&lt;/li&gt;
&lt;li&gt;encoding，标识该对象使用了哪种底层的数据结构;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ptr，指问底层数据结构的指针，&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Redis 键值对数据库的全景图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://L-Y-D-0129.github.io/image/%e5%85%a8%e6%99%af%e5%9b%be.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;sds&#34;&gt;SDS
&lt;/h2&gt;&lt;p&gt;Redis 的String 数据类型的底层数据结构是 SDS。&lt;/p&gt;
&lt;p&gt;之所以设计SDS结构来表示字符串是因为C语言的char*字符数组有以下缺陷：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;char*指针只是指向字符数组的起始位置，而&lt;strong&gt;字符数组的结尾位置就是用&amp;quot;\0&amp;quot;表示，意思是指字符串的结束&lt;/strong&gt;。因此&lt;strong&gt;C语言获取字符串长度的时间复杂度是O(N)（这是一个可以改进的地方）&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;字符串里面不能含有“\0”字符&lt;/strong&gt;，否则最先被程序读入的“\0”字符将被误认为是字符串结尾，这个限制使得C语言的字符串只能保存文本数据，&lt;strong&gt;不能保存像图片、音频、视频文化这样的二进制数据(这也是一个可以改进的地方)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C语言的字符串是不会记录自身的缓冲区大小的&lt;/strong&gt;，所以 strcat 函数假定程序员在执行这个函数时，已经为dest 分配了足够多的内存，可以容纳 src 字符串中的所有内容，而&lt;strong&gt;一旦这个假定不成立，就会发生缓冲区溢出将可能会造成程序运行终止，(这是一个可以改进的地方)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Redis实现的SDS结构可以将上述问题解决。&lt;/p&gt;
&lt;h3 id=&#34;sds结构设计&#34;&gt;SDS结构设计
&lt;/h3&gt;&lt;p&gt;结构中的每个成员变量分别介绍下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;len，记录了字符串长度&lt;/strong&gt;。这样获取字符串长度的时候，只需要返回这个成员变量值就行，时间复杂度只需要 O(1)。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;alloc，分配给字符数组的空间长度&lt;/strong&gt;。这样在修改字符串的时候，可以通过a11oc-len 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足的话，就会自动将 SDS 的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用 SDS 既不需要手动修改 SDS 的空间大小,也不会出现前面所说的缓冲区溢出的问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;flags，用来表示不同类型的 SDS&lt;/strong&gt;。一共设计了5种类型，分别是sdshdr5、sdshdr8、sdshdr16、sdshdr32和 sdshdr64。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;buf[]，字符数组，用来保存实际数据&lt;/strong&gt;。不仅可以保存字符串，也可以保存二进制数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总的来说，Redis 的 SDS 结构在原本字符数组之上，增加了三个元数据:len、aloc、flags，用来解决 C语言字符串的缺陷。&lt;/p&gt;
&lt;p&gt;因此有以下几个优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;O(1)复杂度获取字符串长度
SDS 结构因为加入了 len 成员变量，那么&lt;strong&gt;获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有 O(1)。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;二进制安全
SDS 不需要用 “\0”字符来标识字符串结尾了，而是&lt;strong&gt;有个专门的 len 成员变量来记录长度，所以可存储包含“\0”的数据&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;不会发生缓存区溢出
&lt;strong&gt;当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小&lt;/strong&gt;，且分配额外的「未使用空间」&lt;strong&gt;有效的减少内存分配次数&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;节省内存空间
&lt;strong&gt;不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间&lt;/strong&gt;，并取消了结构体在编译过程中的内存对齐。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;链表&#34;&gt;链表
&lt;/h2&gt;&lt;h3 id=&#34;链表节点结构设计&#34;&gt;链表节点结构设计
&lt;/h3&gt;&lt;p&gt;有前置节点和后置节点，为双向链表。&lt;/p&gt;
&lt;h3 id=&#34;链表结构设计&#34;&gt;链表结构设计
&lt;/h3&gt;&lt;p&gt;Redis在listNode结构体的基础上又封装了list这个数据结构，这样操作起来会更方便。链表结构为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct list {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //链表头节点
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    listNode thead;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //链表尾节点
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    listNode
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *tail;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //节点值复制函数
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    void
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    (*dup)(void
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *ptr);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //节点值释放函数
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    void (*free)(void
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *ptr);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //节点值比较函数
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    int (*match)(void *ptr, void *key);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //链表节点数量
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    unsigned long len;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} list;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;list结构为链表提供了链表头指针head、链表尾节点tail、链表节点数量len、以及可以自定义实现的dup、free、match函数。&lt;/p&gt;
&lt;h3 id=&#34;链表的优势与缺陷&#34;&gt;链表的优势与缺陷
&lt;/h3&gt;&lt;p&gt;Redis的链表实现优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;listNode 链表节点的结构里带有 prev 和 next 指针，&lt;strong&gt;获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;list 结构因为提供了表头指针 head 和表尾节点 tail，所以&lt;strong&gt;获取链表的表头节点和表尾节点的时间复杂度只需O(1)&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;list 结构因为提供了链表节点数量 len，所以&lt;strong&gt;获取链表中的节点数量的时间复杂度只需O(1)&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;listNode 链表节使用 void* 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，&lt;strong&gt;因此链表节点可以保存各种不同类型的值&lt;/strong&gt;；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;链表的缺陷：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;链表每个节点之间的内存都是不连续的，意味着&lt;strong&gt;无法很好利用 CPU 缓存&lt;/strong&gt;。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用CPU 缓存来加速访问。&lt;/li&gt;
&lt;li&gt;还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，&lt;strong&gt;内存开销较大&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，Redis 3.0 的 List 对象在数据量比较少的情况下，会采用「压缩列表」作为底层数据结构的实现，它的优势是节省内存空间，并且是内存紧凑型的数据结构。&lt;/p&gt;
&lt;p&gt;不过，压缩列表存在性能问题，所以 Redis 在 3.2 版本设计了新的数据结构quicklist，并将 List 对象的底层数据结构改由 quicklist 实现。&lt;/p&gt;
&lt;p&gt;然后在 Redis 5.0 设计了新的数据结构listpack，沿用了压缩列表紧凑型的内存布局，最终在最新的 Redis版本，将 Hash 对象和 Zset 对象的底层数据结构实现之一的压缩列表，替换成由 listpack 实现。&lt;/p&gt;
&lt;h2 id=&#34;压缩列表&#34;&gt;压缩列表
&lt;/h2&gt;&lt;p&gt;压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。&lt;/p&gt;
&lt;p&gt;但是，压缩列表的缺陷也是有的:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不能保存过多的元素，否则查询效率就会降低;&lt;/li&gt;
&lt;li&gt;新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，甚至可能引发连锁更新的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，Redis 对象(List 对象、Hash 对象、Zset 对象)包含的元素数量较少，或者元素值不大的情况才会使用压缩列表作为底层数据结构。&lt;/p&gt;
&lt;h3 id=&#34;压缩列表结构设计&#34;&gt;压缩列表结构设计
&lt;/h3&gt;&lt;p&gt;压缩列表是Redis为了节约内存而开发的，它是&lt;strong&gt;由连续内存块组成的顺序型数据结构&lt;/strong&gt;，有点类似于数组。&lt;/p&gt;
&lt;p&gt;压缩列表在表头有三个字段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;zlbytes&lt;/strong&gt;，记录整个压缩列表占用对内存字节数;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zltail&lt;/strong&gt;，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zllen&lt;/strong&gt;，记录压缩列表包含的节点数量;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;zlend&lt;/strong&gt;，标记压缩列表的结束点，固定值 0xFF(十进制255)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段(zllen)的长度直接定位，复杂度是 0(1)。而&lt;strong&gt;查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是O(N)了，因此压缩列表不适合保存过多的元素&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;压缩列表节点（entry）包含三部分内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;prevlen&lt;/strong&gt;，记录了「前一个节点」的长度，目的是为了实现从后向前遍历;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;encoding&lt;/strong&gt;，记录了当前节点实际数据的「类型和长度」，类型主要有两种:字符串和整数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;data&lt;/strong&gt;，记录了当前节点的实际数据，类型和长度都由encoding 决定;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当我们往压缩列表中插入数据时，压缩列表就会根据数据类型是字符串还是整数，以及数据的大小，会使用不同空间大小的 preven 和 encoding 这两个元素里保存的信息，&lt;strong&gt;这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分别说下，prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配。&lt;/p&gt;
&lt;p&gt;压缩列表里的每个节点中的 prevlen 属性都记录了「前一个节点的长度|，而且 prevlen 属性的空间大小&lt;/p&gt;
&lt;p&gt;跟前一个节点长度值有关，比如:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果前一个节点的长度小于 254 字节，那么 preven 属性需要用1字节的空间来保存这个长度值;&lt;/li&gt;
&lt;li&gt;如果前一个节点的长度大于等于 254 字节，那么 previen 属性需要用5 字节的空间来保存这个长度值;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;encoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果&lt;strong&gt;当前节点的数据是整数&lt;/strong&gt;，则 encoding 会使用&lt;strong&gt;1字节的空间&lt;/strong&gt;进行编码，也就是 encoding 长度为 1字节。通过 encoding 确认了整数类型，就可以确认整数数据的实际大小了，比如如果 encoding 编码确认了数据是 int16 整数，那么 data 的长度就是 int16 的大小。&lt;/li&gt;
&lt;li&gt;如果&lt;strong&gt;当前节点的数据是字符串，根据字符串的长度大小&lt;/strong&gt;，encoding 会使用&lt;strong&gt;1字节/2字节/5字节的空间&lt;/strong&gt;进行编码，encoding 编码的前两个 bit 表示数据的类型，后续的其他 bit 标识字符串数据的实际长度即 data 的长度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;压缩列表的缺陷&#34;&gt;压缩列表的缺陷
&lt;/h3&gt;&lt;p&gt;空间扩展操作也就是重新分配内存，因此&lt;strong&gt;连锁更新一旦发生，就会导致压缩列表占用的内存空间要多次重新分配，这就会直接影响到压缩列表的访问性能。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所以说，&lt;strong&gt;虽然压缩列表紧凑型的内存布局能节省内存开销，但是如果保存的元素数量增加了，或是元素变大了，会导致内存重新分配，最糟糕的是会有「连锁更新」的问题。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此，&lt;strong&gt;压缩列表只会用于保存的节点数量不多的场景&lt;/strong&gt;，只要节点数量足够小，即使发生连锁更新，也是能接受的。&lt;/p&gt;
&lt;p&gt;虽说如此，Redis 针对压缩列表在设计上的不足，在后来的版本中，新增设计了两种数据结构:quicklist(Redis 3.2 引入)和 listpack(Redis 5.0 引入)。这两种数据结构的设计目标，就是尽可能地保持压缩列表节省内存的优势，同时解决压缩列表的「连锁更新」的问题。&lt;/p&gt;
&lt;h4 id=&#34;连锁更新问题&#34;&gt;连锁更新问题
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;压缩列表新增某个元素或修改某个元素时，如果空间不够，压缩列表占用的内存空间就需要重新分配,而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这种在特殊情况下产生的连续多次空间扩展操作就叫做「连锁更新」&lt;/strong&gt;，就像多米诺牌的效应一样。&lt;/p&gt;
&lt;h2 id=&#34;哈希表&#34;&gt;哈希表
&lt;/h2&gt;&lt;p&gt;哈希表是一种保存键值对(key-value)的数据结构。&lt;/p&gt;
&lt;p&gt;哈希表中的每一个 key 都是独一无二的，程序可以根据 key 查找到与之关联的 value，或者通过 key 来更新 value，又或者根据 key 来删除整个 key-value等等。&lt;/p&gt;
&lt;p&gt;优点：&lt;strong&gt;以 O(1)的复杂度快速查询数据&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;缺点：在哈希表大小固定的情况下，随着数据不断增多，那么&lt;strong&gt;哈希冲突&lt;/strong&gt;的可能性也会越高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Redis 采用了「链式哈希」来解决哈希冲突&lt;/strong&gt;，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接起，以便这些数据在表中仍然可以被查询到。&lt;/p&gt;
&lt;h3 id=&#34;哈希表结构设计&#34;&gt;哈希表结构设计
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct dictht {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //哈希表数组
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    dictEntry
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    table;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //哈希表大小
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    unsigned long size;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //哈希表大小掩码,用于计算索引值
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    unsigned long sizemask;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //该哈希表已有的节点数量
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    unsigned long used;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}dictht;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;可以看到，哈希表是一个数组(dictEntry **table)，数组的每个元素是一个指向「哈希表节点(dictEntry)」的指针。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://L-Y-D-0129.github.io/image/%e5%93%88%e5%b8%8c%e8%a1%a8.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;哈希表节点的结构如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct dictEntry {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //键值对中的键
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    void *key;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //键值对中的值
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    union (
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    void *val;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    uint64_t u64;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    int64_t s64;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    double d;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    } v;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //指向下一个哈希表节点,形成链表
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    struct dictEntry next;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} dictentry;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;dictEntry 结构里不仅包含指向键和值的指针，还包含了指向下一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对链接起来，以此来解决哈希冲突的问题，这就是链式哈希。&lt;/p&gt;
&lt;h3 id=&#34;哈希冲突&#34;&gt;哈希冲突
&lt;/h3&gt;&lt;p&gt;哈希表实际上是一个数组，数组里的每一个元素就是一个哈希桶。&lt;/p&gt;
&lt;p&gt;当一个键值对的键经过 Hash 函数计算后得到哈希值，再将(哈希值 % 哈希表大小)取模计算，得到的结果值就是该 key-value 对应的数组元素位置，也就是第几个哈希桶。、&lt;/p&gt;
&lt;h4 id=&#34;什么是哈希冲突呢&#34;&gt;什么是哈希冲突呢
&lt;/h4&gt;&lt;p&gt;举个例子，有一个可以存放8个哈希桶的哈希表。key1 经过哈希函数计算后，再将「哈希值%8」进行取模计算，结果值为 1，那么就对应哈希桶 1，类似的，key9 和 key10 分别对应哈希桶1和桶 6。&lt;/p&gt;
&lt;p&gt;此时，key1 和 key9 对应到了相同的哈希桶中，这就发生了哈希冲突。&lt;/p&gt;
&lt;p&gt;因此，&lt;strong&gt;当有两个以上数量的 kay 被分配到了哈希表中同一个哈希桶上时，此时称这些 key 发生了冲突。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;链式哈希&#34;&gt;链式哈希
&lt;/h3&gt;&lt;p&gt;Redis采用了链式哈希的方法解决哈希冲突。&lt;/p&gt;
&lt;h4 id=&#34;链式哈希怎么实现的&#34;&gt;链式哈希怎么实现的？
&lt;/h4&gt;&lt;p&gt;实现的方式就是每个哈希表节点都有一个 next 指针，用于指向下一个哈希表节点，因此多个哈希表节点可以用 next 指针构成一个单项链表，&lt;strong&gt;被分配到同一个哈希桶上的多个节点可以用这个单项链表连接起来，这样就解决了哈希冲突。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;还是用前面的哈希冲突例子，key1 和 key9 经过哈希计算后，都落在同一个哈希桶，链式哈希的话，key1就会通过 next 指针指向 key9，形成一个单向链表。&lt;/p&gt;
&lt;p&gt;不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O(n)。&lt;/p&gt;
&lt;p&gt;要想解决这一问题，就需要进行rehash，也就是对哈希表的大小进行扩展。&lt;/p&gt;
&lt;h3 id=&#34;rehash&#34;&gt;rehash
&lt;/h3&gt;&lt;p&gt;在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了两个哈希表(ht[2])。&lt;/p&gt;
&lt;p&gt;之所以定义了两个哈希表，是因为进行rehash的时候，需要用上两个哈希表。&lt;/p&gt;
&lt;p&gt;在正常服务请求阶段，插入的数据，都会写入到「哈希表1」，此时的「哈希表2」 并没有被分配空间。&lt;/p&gt;
&lt;p&gt;随着数据逐步增多，触发了 rehash 操作，这个过程分为三步:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;·给「哈希表 2」分配空间，一般会比「哈希表1」大一倍(两倍的意思);&lt;/li&gt;
&lt;li&gt;将「哈希表1」的数据迁移到「哈希表 2」 中;&lt;/li&gt;
&lt;li&gt;迁移完成后，「哈希表1」的空间会被释放，并把「哈希表 2」设置为「哈希表1」，然后在「哈希表2」 新创建一个空白的哈希表，为下次 rehash 做准备。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个过程看起来简单，但是其实第二步很有问题，&lt;strong&gt;如果哈希表1的数据非常庞大，那么在迁移至哈希表2的时候，因为会涉及大量的数据拷贝，此时可能会对Redis造成阻塞，无法服务其他请求。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;渐进式rehash&#34;&gt;渐进式rehash
&lt;/h3&gt;&lt;p&gt;为了避免 rehash 在数据迁移过程中，因拷贝数据的耗时，影响 Redis 性能的情况，所以 Redis 采用了渐进式 rehash，也就是将数据的迁移的工作不再是一次性迁移完成，而是分多次迁移。&lt;/p&gt;
&lt;p&gt;渐进式 rehash 步骤如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给「哈希表 2」分配空间;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表1」中索引位置上的所有 key-value 迁移到「哈希表 2」 上;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表1」的所有 keyvalue 迁移到「哈希表 2」，从而完成 rehash 操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样就巧妙地把一次性大量数据迁移工作的开销，分摊到了多次处理请求的过程中，避免了一次性 rehash的耗时操作。&lt;/p&gt;
&lt;p&gt;在进行渐进式 rehash 的过程中，会有两个哈希表，所以在渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行。&lt;/p&gt;
&lt;p&gt;比如，查找一个 key 的值的话，先会在「哈希表1」里面进行查找，如果没找到，就会继续到哈希表2里面进行找到。&lt;/p&gt;
&lt;p&gt;另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表2」里面，而「哈希表1」则不再进行任何添加操作，这样保证了「哈希表1」的 key-value 数量只会减少，随着 rehash 操作的完成，最终「哈希表1」就会变成空表，&lt;/p&gt;
&lt;p&gt;而rehash 的触发条件跟**负载因子(load factor)**有关系。&lt;/p&gt;
&lt;p&gt;负载因子可以通过下面这个公式计算:
&lt;/p&gt;
$$
                            负载因子 = 哈希表已保存节点数量 / 哈希表大小
$$&lt;p&gt;
触发 rehash 操作的条件，主要有两个:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;当负载因子大于等于1，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当负载因子大于等于5时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;整数集合&#34;&gt;整数集合
&lt;/h2&gt;&lt;p&gt;整数集合是 Set 对象的底层实现之一。当一个 Set 对象只包含整数值元素，并且元素数量不大时，就会使用整数集这个数据结构作为底层实现。&lt;/p&gt;
&lt;h3 id=&#34;整数集合结构设计&#34;&gt;整数集合结构设计
&lt;/h3&gt;&lt;p&gt;整数集合的本质是一块连续内存空间，它的结构定义如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct intset {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //编码方式
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    uint32_t encoding
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //集合包含的元素数量
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    uint32 t length;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //保存元素的数组
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    int8_t contents[];
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}intset;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;可以看到，保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的encoding 属性的值。比如:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果 encoding 属性值为 INTSET_ENC INT16，那么 contents 就是一个 int16_t类型的数组，数组中每一个元素的类型都是 int16_t;&lt;/li&gt;
&lt;li&gt;如果 encoding 属性值为 INTSET_ENC_INT32，那么 contents 就是一个 int32_t类型的数组，数组中每一个元素的类型都是 int32_t;&lt;/li&gt;
&lt;li&gt;如果 encoding 属性值为 INTSET_ENC_INT64，那么 contents 就是一个 int64_t类型的数组，数组中每-个元素的类型都是 int64_t;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不同类型的 contents 数组，意味着数组的大小也会不同。&lt;/p&gt;
&lt;h3 id=&#34;整数集合的升级操作&#34;&gt;整数集合的升级操作
&lt;/h3&gt;&lt;p&gt;整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型(int32_t)比整数集合现有所有元素的类型(int16_t)都要长时，整数集合需要先进行升级，也就是按新元素的类型(int32_t)扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;整数集合升级的过程不会重新分配一个新类型的数组，而是在原本的数组上扩展空间，然后在将每个元素按间隔类型大小分割，如果 encoding 属性值为 INTSET_ENC_INT16，则每个元素的间隔就是 16 位。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;整数集合升级有什么好处呢&#34;&gt;整数集合升级有什么好处呢？
&lt;/h4&gt;&lt;p&gt;如果要让一个数组同时保存 int16_t、int32_t、int64_t 类型的元素，最简单做法就是直接使用 int64_t 类型的数组。不过这样的话，当如果元素都是 int16_t 类型的，就会造成内存浪费的情况。&lt;/p&gt;
&lt;p&gt;整数集合升级就能避免这种情况，如果一直向整数集合添加 int16_t 类型的元素，那么整数集合的底层实现就一直是用 int16_t 类型的数组，只有在我们要将 int32_t 类型或 int64_t 类型的元素添加到集合时，才会对数组进行升级操作。&lt;/p&gt;
&lt;p&gt;因此，整数集合升级的好处是节省内存资源。&lt;/p&gt;
&lt;h4 id=&#34;整数集合支持降级操作吗&#34;&gt;整数集合支持降级操作吗？
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;不支持降级操作&lt;/strong&gt;，一旦对数组进行了升级，就会一直保持升级后的状态。&lt;/p&gt;
&lt;h2 id=&#34;跳表&#34;&gt;跳表
&lt;/h2&gt;&lt;p&gt;Redis 只有 Zset 对象的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。&lt;/p&gt;
&lt;p&gt;zset 结构体里有两个数据结构：一个是跳表，一个是哈希表。这样的好处是既能进行高效的范围查询，也能进行高效单点查询。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct zset {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    dict *dict;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    zskiplist *zsl;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} zset;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;set 对象在执行数据插入或是数据更新的过程中，会依次在跳表和哈希表中插入或更新相应的数据，从而保证了跳表和哈希表中记录的信息一致。&lt;/p&gt;
&lt;p&gt;Zset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了&lt;strong&gt;跳表&lt;/strong&gt;，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时采用了&lt;strong&gt;哈希表&lt;/strong&gt;进行索引。&lt;/p&gt;
&lt;p&gt;虽然Zset 对象在使用跳表作为数据结构的时候，是使用由「哈希表+跳表」组成的 struct zset，但是struct zset 中的哈希表只是用于以常数复杂度获取元素权重，其余大部分操作都是跳表实现的。&lt;/p&gt;
&lt;h3 id=&#34;跳表结构设计&#34;&gt;跳表结构设计
&lt;/h3&gt;&lt;p&gt;链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。&lt;strong&gt;跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表&lt;/strong&gt;，这样的好处是能快读定位数据。&lt;/p&gt;
&lt;p&gt;图中头节点有 L0~L2 三个头指针，分别指向了不同层级的节点，然后每个层级的节点都通过指针连接起来：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L0 层级共有 5 个节点，分别是节点1、2、3、4、5；&lt;/li&gt;
&lt;li&gt;L1 层级共有 3 个节点，分别是节点 2、3、5；&lt;/li&gt;
&lt;li&gt;L2 层级只有 1 个节点，也就是节点 3 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果我们要在链表中查找节点 4 这个元素，只能从头开始遍历链表，需要查找 4 次，而使用了跳表后，只需要查找 2 次就能定位到节点 4，因为可以在头节点直接从 L2 层级跳到节点 3，然后再往前遍历找到节点 4。&lt;/p&gt;
&lt;p&gt;可以看到，这个查找过程就是在多个层级上跳来跳去，最后定位到元素。当数据量很大时，跳表的查找复杂度就是 O(logN)。&lt;/p&gt;
&lt;p&gt;跳表节点数据结构：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct zskiplistNode {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //Zset 对象的元素值
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    sds ele
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //元素权重值
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    double score;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //后向指针
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    struct zskiplistNode *backward;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    //节点的level数组，保存每层上的前向指针和跨度
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    struct zskiplistLevel {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        struct zskiplistNode *forward;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        unsigned long span;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    } level[];
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} zskiplistNode;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Zset 对象要同时保存「元素」和「元素的权重」，对应到跳表节点结构里就是 sds 类型的 ele 变量和 double 类型的 score 变量。每个跳表节点都有一个后向指针（struct zskiplistNode *backward），指向前一个节点，目的是为了方便从跳表的尾节点开始访问节点，这样倒序查找时很方便。&lt;/p&gt;
&lt;p&gt;跳表是一个带有层级关系的链表，而且每一层级可以包含多个节点，每一个节点通过指针连接起来，实现这一特性就是靠跳表节点结构体中的zskiplistLevel 结构体类型的 level 数组。&lt;/p&gt;
&lt;p&gt;level 数组中的每一个元素代表跳表的一层，也就是由 zskiplistLevel 结构体表示，比如 leve[0] 就表示第一层，leve[1] 就表示第二层。zskiplistLevel 结构体里定义了「指向下一个跳表节点的指针」和「跨度」，跨度时用来记录两个节点之间的距离。&lt;/p&gt;
&lt;p&gt;**跨度实际上是为了计算这个节点在跳表中的排位。**具体怎么做的呢？因为跳表中的节点都是按序排列的，那么计算某个节点排位的时候，从头节点点到该结点的查询路径上，将沿途访问过的所有层的跨度累加起来，得到的结果就是目标节点在跳表中的排位。&lt;/p&gt;
&lt;p&gt;跳表结构体：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;typedef struct zskiplist {
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    struct zskiplistNode *header, *tail;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    unsigned long length;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    int level;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} zskiplist;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;跳表结构里包含了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跳表的头尾节点，便于在O(1)时间复杂度内访问跳表的头节点和尾节点；&lt;/li&gt;
&lt;li&gt;跳表的长度，便于在O(1)时间复杂度获取跳表节点的数量；&lt;/li&gt;
&lt;li&gt;跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;跳表节点查询过程&#34;&gt;跳表节点查询过程
&lt;/h3&gt;&lt;p&gt;查找一个跳表节点的过程时，跳表会从头节点的最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。&lt;/li&gt;
&lt;li&gt;如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。&lt;/p&gt;
&lt;h3 id=&#34;跳表节点层数设置&#34;&gt;跳表节点层数设置
&lt;/h3&gt;&lt;p&gt;跳表的相邻两层的节点数量的比例会影响跳表的查询性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;跳表的相邻两层的节点数量最理想的比例是 2:1，查找复杂度可以降低到 O(logN)。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;那怎样才能维持相邻两层的节点数量的比例为-2--1-呢&#34;&gt;那怎样才能维持相邻两层的节点数量的比例为 2 : 1 呢？
&lt;/h4&gt;&lt;p&gt;如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。&lt;/p&gt;
&lt;p&gt;Redis 则采用一种巧妙的方法是，&lt;strong&gt;跳表在创建节点的时候，随机生成每个节点的层数&lt;/strong&gt;，并没有严格维持相邻两层的节点数量比例为 2 : 1 的情况。&lt;/p&gt;
&lt;p&gt;具体的做法是，&lt;strong&gt;跳表在创建节点时候，会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束，最终确定该节点的层数。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这样的做法，相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。&lt;/p&gt;
&lt;p&gt;虽然我前面讲解跳表的时候，图中的跳表的「头节点」都是 3 层高，&lt;strong&gt;但是其实如果层高最大限制是 64，那么在创建跳表「头节点」的时候，就会直接创建 64 层高的头节点&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;为什么用跳表而不用平衡树&#34;&gt;为什么用跳表而不用平衡树？
&lt;/h3&gt;&lt;p&gt;主要是从内存占用、对范围查找的支持、实现难易程度这三方面总结的原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**从内存占用上来比较，跳表比平衡树更灵活一些。**平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。&lt;/li&gt;
&lt;li&gt;**在做范围查找的时候，跳表比平衡树操作要简单。**在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;从算法实现难度上来比较，跳表比平衡树要简单得多&lt;/strong&gt;。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;quicklist&#34;&gt;quicklist
&lt;/h2&gt;&lt;p&gt;在 Redis 3.0 之前，List 对象的底层数据结构是双向链表或者压缩列表。然后在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。&lt;/p&gt;
&lt;p&gt;其实 quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。&lt;/p&gt;
&lt;p&gt;在前面讲压缩列表的时候，我也提到了压缩列表的不足，虽然压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。&lt;/p&gt;
&lt;p&gt;quicklist 解决办法，&lt;strong&gt;通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;listpack&#34;&gt;listpack
&lt;/h2&gt;&lt;p&gt;quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。&lt;/p&gt;
&lt;p&gt;因为 quicklistNode 还是用了压缩列表来保存元素，压缩列表连锁更新的问题，来源于它的结构设计，所以要想彻底解决这个问题，需要设计一个新的数据结构。&lt;/p&gt;
&lt;p&gt;于是，Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;图片出处为小林coding&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;aof持久化&#34;&gt;AOF持久化
&lt;/h1&gt;&lt;p&gt;AOF文件的内容是操作命令&lt;/p&gt;
&lt;h2 id=&#34;aof日志&#34;&gt;AOF日志
&lt;/h2&gt;&lt;p&gt;其思想是Redis每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，重启 Redis 的时候，先去读取这个文件里的命令，并且执行它，就相当于恢复了缓存数据了。&lt;/p&gt;
&lt;p&gt;客户端发送写命令到Redis。第一步执行写命令到内存；第二步记录命令到日志，日志存放到硬盘。&lt;/p&gt;
&lt;p&gt;这种保存写操作命令到日志的持久化方式，就是Redis里的&lt;strong&gt;AOF&lt;/strong&gt;（Append Only File）持久化功能，&lt;strong&gt;注意只会记录写操作命令，读操作命令是不会被记录的&lt;/strong&gt;，因为没意义。&lt;/p&gt;
&lt;p&gt;在Redis中AOF持久化功能默认是不开启的。&lt;/p&gt;
&lt;p&gt;AOF日志文件其实就是普通的文本，我们可以通过cat命令查看里面的内容，但其中记录的内容有一定的阅读规则。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;*3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;set
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;name
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$7xiaoxin
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。&lt;/p&gt;
&lt;p&gt;Redis先执行写操作命令后，再将命令记录到AOF日志里，有以下两个好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;避免额外的检查开销&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。&lt;/p&gt;
&lt;p&gt;而如果先执行写操作命令再记录日志的话，只有在该命令执行成功后，才将命令记录到 AOF 日志里，这样就不用额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;不会阻塞当前写操作命令的执行&lt;/strong&gt;
当写操作命令执行成功后，才会将命令记录到 AOF 日志。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两个风险：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有&lt;strong&gt;丢失的风险&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是&lt;strong&gt;可能会给「下一个」命令带来阻塞风险&lt;/strong&gt;。因为将命令写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程），也就是说这两个操作是同步的。如果在将日志内容写入到硬盘时，服务器的硬盘的 I/O 压力太大，就会导致写硬盘的速度很慢，进而阻塞住了，也就会导致后续的命令无法执行。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两个风险的共性就是跟「 AOF 日志写回硬盘的时机」有关。&lt;/p&gt;
&lt;h2 id=&#34;三种写回策略&#34;&gt;三种写回策略
&lt;/h2&gt;&lt;p&gt;Redis写入AOF日志过程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://L-Y-D-0129.github.io/image/AOF%e8%bf%87%e7%a8%8b.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区；&lt;/li&gt;
&lt;li&gt;然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；&lt;/li&gt;
&lt;li&gt;具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Redis 提供了 3 种写回硬盘的策略，控制的就是上面说的第三步的过程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Always&lt;/strong&gt;，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Everysec&lt;/strong&gt;，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No&lt;/strong&gt;，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这 3 种写回策略都无法能完美解决「主进程阻塞」和「减少数据丢失」的问题，因为两个问题是对立的，偏向于一边的话，就会要牺牲另外一边，原因如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Always 策略的话，可以最大程度保证数据不丢失，但是由于它每执行一条写操作命令就同步将 AOF 内容写回硬盘，所以是不可避免会影响主进程的性能；&lt;/li&gt;
&lt;li&gt;No 策略的话，是交由操作系统来决定何时将 AOF 日志内容写回硬盘，相比于 Always 策略性能较好，但是操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失不定数量的数据。&lt;/li&gt;
&lt;li&gt;Everysec 策略的话，是折中的一种方式，避免了 Always 策略的性能开销，也比 No 策略更能避免数据丢失，当然如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据自己的业务场景进行选择：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果要高性能，就选择 No 策略；&lt;/li&gt;
&lt;li&gt;如果要高可靠，就选择 Always 策略；&lt;/li&gt;
&lt;li&gt;如果允许数据丢失一点，但又想性能高，就选择 Everysec 策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;以上三种策略其实是在控制fsync()函数的调用时机：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 fsync() 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；&lt;/li&gt;
&lt;li&gt;Everysec 策略就会创建一个异步任务来执行 fsync() 函数；&lt;/li&gt;
&lt;li&gt;No 策略就是永不执行 fsync() 函数&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aof重写机制&#34;&gt;AOF重写机制
&lt;/h2&gt;&lt;p&gt;AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。&lt;/p&gt;
&lt;p&gt;如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。&lt;/p&gt;
&lt;p&gt;所以，Redis 为了避免 AOF 文件越写越大，提供了 &lt;strong&gt;AOF 重写机制&lt;/strong&gt;，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。&lt;/p&gt;
&lt;p&gt;AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。&lt;/p&gt;
&lt;p&gt;重写工作完成后，就会将新的 AOF 文件覆盖现有的 AOF 文件，这就相当于压缩了 AOF 文件，使得 AOF 文件体积变小了。&lt;/p&gt;
&lt;p&gt;然后，在通过 AOF 日志恢复数据时，只用执行这条命令，就可以直接完成这个键值对的写入了。&lt;/p&gt;
&lt;p&gt;所以，重写机制的妙处在于，尽管某个键值对被多条写命令反复修改，&lt;strong&gt;最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对&lt;/strong&gt;，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量。最后在重写工作完成后，将新的 AOF 文件覆盖现有的 AOF 文件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为&lt;strong&gt;如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染&lt;/strong&gt;，可能无法用于恢复使用。&lt;/p&gt;
&lt;p&gt;所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响。&lt;/p&gt;
&lt;h2 id=&#34;aof后台重写&#34;&gt;AOF后台重写
&lt;/h2&gt;&lt;p&gt;写入 AOF 日志的操作虽然是在主进程完成的，因为它写入的内容不多，所以一般不太影响命令的操作。&lt;/p&gt;
&lt;p&gt;但重写这个过程其实是很耗时的，因为需要读取所有缓存的键值对数据，并为每个键值对生成一条命令，然后将其写入到新的 AOF 文件。所以重写的操作不能放在主进程里。&lt;/p&gt;
&lt;p&gt;因此，Redis 的&lt;strong&gt;重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的&lt;/strong&gt;，这么做可以达到两个好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；&lt;/li&gt;
&lt;li&gt;子进程带有主进程的&lt;strong&gt;数据副本&lt;/strong&gt;，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;子进程是怎么拥有主进程一样的数据副本的呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「&lt;strong&gt;页表&lt;/strong&gt;」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。&lt;/p&gt;
&lt;p&gt;这样一来，子进程就共享了父进程的物理内存数据了，这样能够&lt;strong&gt;节约物理内存资源&lt;/strong&gt;，页表对应的页表项的属性会标记该物理内存的权限为&lt;strong&gt;只读&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发&lt;strong&gt;写保护中断&lt;/strong&gt;，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行&lt;strong&gt;物理内存的复制&lt;/strong&gt;，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「&lt;strong&gt;写时复制(Copy On Write)&lt;/strong&gt;」。&lt;/p&gt;
&lt;p&gt;写时复制顾名思义，&lt;strong&gt;在发生写操作的时候，操作系统才会去复制物理内存&lt;/strong&gt;，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长而导致父进程长时间阻塞的问题。&lt;/p&gt;
&lt;h2 id=&#34;总结-1&#34;&gt;总结
&lt;/h2&gt;&lt;p&gt;Redis 提供了三种将 AOF 日志写回硬盘的策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。&lt;/p&gt;
&lt;p&gt;随着执行的命令越多，AOF 文件的体积自然也会越来越大，为了避免日志文件过大， Redis 提供了 AOF 重写机制，它会直接扫描数据中所有的键值对数据，然后为每一个键值对生成一条写操作命令，接着将该命令写入到新的 AOF 文件，重写完成后，就替换掉现有的 AOF 日志。重写的过程是由后台子进程完成的，这样可以使得主进程可以继续正常处理命令。&lt;/p&gt;
&lt;p&gt;用 AOF 日志的方式来恢复数据其实是很慢的，因为 Redis 执行命令由单线程负责的，而 AOF 日志恢复数据的方式是顺序执行日志里的每一条命令，如果 AOF 日志很大，这个「重放」的过程就会很慢了。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>C&#43;&#43;</title>
        <link>https://L-Y-D-0129.github.io/p/c-/</link>
        <pubDate>Fri, 15 Sep 2023 17:34:23 +0800</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/p/c-/</guid>
        <description>&lt;img src="https://L-Y-D-0129.github.io/p/c-/21092500555TF2-0-lp.jpg" alt="Featured image of post C&#43;&#43;" /&gt;&lt;h2 id=&#34;c知识点&#34;&gt;C++知识点
&lt;/h2&gt;&lt;h3 id=&#34;c语言与c的区别&#34;&gt;C语言与C++的区别
&lt;/h3&gt;&lt;p&gt;C语言没有bool类型 C++有 C++可以重载和c没有&lt;br /&gt;
这是因为C++的编译器在编译的时候会带着函数参数的类型 C语言不会
C++是面向对象编程 C是面向过程&lt;br /&gt;
C++ 变量检测增强  例如 在全局 定义一个变量 为 int a； 然后还在全局对他初始化 int a=4；这时会报错 但C不会&lt;br /&gt;
默认返回值不同 在c++中若函数没有返回值 则必须指定为void  c没有的话默认为int&lt;br /&gt;
C++有缺省参数 c没有&lt;br /&gt;
C语言中作用域只有两个：局部，全局。C++中则是有：局部作用域，类作用域，名字空间作用域三种。&lt;/p&gt;
&lt;h3 id=&#34;菱形继承&#34;&gt;菱形继承
&lt;/h3&gt;&lt;p&gt;类A,类B，类C都继承A，然后类D继承自类和类C，&lt;/p&gt;
&lt;h4 id=&#34;会产生数据冗余&#34;&gt;会产生数据冗余
&lt;/h4&gt;&lt;p&gt;类A有一些数据成员，类B和类C继承于A，类B和类C都会有一份自类A的数据副本，当类D继承自类B和类C时，类D实际会有两份来自类A的数据副本，造成数据冗余。&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;二义性&#34;&gt;二义性
&lt;/h4&gt;&lt;p&gt;当类 D 中调用一个在类 A 中定义的方法时，由于类 D 有两条通过类 B 和类 C 到达类 A 的继承路径，编译器无法确定应该使用哪一条路径上的方法，从而导致二义性问题。&lt;br /&gt;
可以通过虚继承来解决菱形继承
用类B和类C以虚继承的方式继承类A时，类D只会有一份来自类A的数据副本。&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;malloc是如何分配内存的&#34;&gt;malloc是如何分配内存的
&lt;/h3&gt;&lt;p&gt;1.通过brk系统调用从堆分配内存&lt;br /&gt;
2.通过mmap系统调用在文件映射区域分配内存&lt;br /&gt;
malloc分配的是虚拟内存&lt;br /&gt;
他会预分配更大的空间作为内存池&lt;br /&gt;
malloc通过brk方式申请的内存，free释放的时候，并不会把内存归还给操作系统，而是缓存在malloc的内存池中&lt;br /&gt;
malloc通过mmap方式申请的内存，free释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;volatile关键字&#34;&gt;volatile关键字
&lt;/h3&gt;&lt;p&gt;提醒编译器他后面所定义的变量随时都有可能被改变，因此编译后的程序每次需要存储或读取这个变量的时候，都会直接从变量地址中读取数据。如果没有volatile关键字，则编译器可能优化读取和存储，可能暂时使用寄存器中的值&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;c将引用作为返回值的好处和应该遵守的规则&#34;&gt;C++将引用作为返回值的好处和应该遵守的规则
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;减少内存开销&lt;/li&gt;
&lt;li&gt;提高效率&lt;/li&gt;
&lt;li&gt;支持链式操作&lt;/li&gt;
&lt;li&gt;注意不能返回局部变量的引用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;union和struct的区别&#34;&gt;union和struct的区别
&lt;/h3&gt;&lt;h4 id=&#34;struct&#34;&gt;struct
&lt;/h4&gt;&lt;p&gt;各成员拥有自己的内存，各自使用互不干涉，同时存在遵循内存对齐原则，一个struct变量总长度等于所有成员的长度之和&lt;/p&gt;
&lt;h4 id=&#34;union&#34;&gt;union
&lt;/h4&gt;&lt;p&gt;各成员共用一块内存空间，并且同时只有一个成员可以得到这块内存的使用权，各变量共用一个内存首地址，联合体比结构体更节约内存，一个union变量的总长度至少能容纳最大的成员变量，而且要满足是所有成员变量类型大小的整数倍。
在赋值的时候，对于union的不同成员赋值，将会对其他成员进行重写，原来成员的值就不存在了，而对于struct的不同成员赋值是互不影响的。&lt;/p&gt;
&lt;h3 id=&#34;四种强制类型转换&#34;&gt;四种强制类型转换
&lt;/h3&gt;&lt;h4 id=&#34;static_cast&#34;&gt;static_cast
&lt;/h4&gt;&lt;p&gt;用于将一种数据类型强制转换为另一种数据类型&lt;/p&gt;
&lt;h4 id=&#34;const_cast&#34;&gt;const_cast
&lt;/h4&gt;&lt;p&gt;用于强制去掉不能被修改的常数特性，但需要特别主义的是const_cast不是用于去除变量的常量性，而是去除指向常数对象的指针或引用的常量性，其去除常量性的对象必须为指针或引用。&lt;/p&gt;
&lt;h4 id=&#34;reinterpret_cast&#34;&gt;reinterpret_cast
&lt;/h4&gt;&lt;p&gt;改变指针或引用的类型，指针或引用转换为一个足够长度的整形，将整形转换为指针或引用类型&lt;/p&gt;
&lt;h4 id=&#34;dynamic_cast&#34;&gt;dynamic_cast
&lt;/h4&gt;&lt;p&gt;将基类的指针或引用安全地转换成派生类的指针或引用，并用派生类的指针或引用调用非虚函数。如果是基类指针或引用调用的是虚函数无需转换就能在运行时调用派生类的虚函数&lt;/p&gt;
&lt;h4 id=&#34;dynamic_cast-1&#34;&gt;dynamic_cast
&lt;/h4&gt;&lt;p&gt;的实现原理涉及到一个名为 &amp;ldquo;vtable&amp;rdquo; 的虚函数表和一个名为 &amp;ldquo;type_info&amp;rdquo; 的运行时类型信息 (RTTI) 系统。&lt;/p&gt;
&lt;h3 id=&#34;迭代器失效&#34;&gt;迭代器失效
&lt;/h3&gt;&lt;p&gt;迭代器：是一个遍历各种容器内元素的访问。
它的底层是一个指针 类模板
迭代器失效：就是迭代器底层对应指针所指向的空间被销毁了，而使用一块已经被释放的空间，造成的后果是程序崩溃。
可能会引起的扩容操作都有可能导致迭代器失效，push_back什么的&lt;/p&gt;
&lt;h3 id=&#34;this指针&#34;&gt;this指针
&lt;/h3&gt;&lt;p&gt;this指针存在于类成员函数中，指向类对象的指针。this是一个关键字，同时也是一个指针常量。
成员函数调用时，传递了一个隐含的参数指向函数所在类对象的地址。&lt;br /&gt;
this在成员在成员函数的开始执行前构造，在成员的执行结束后清除。&lt;br /&gt;
悬空指针是指向被释放内存的指针，而野指针是不确定其具体指向的指针&lt;/p&gt;
&lt;h3 id=&#34;用户态与内核态&#34;&gt;用户态与内核态
&lt;/h3&gt;&lt;p&gt;内核态控制的是内核空间的资源管理，用户态访问的是用户空间内的资源
指令的划分 特权不同
用户态&amp;mdash;&amp;gt;内核态：唯一途径是通过中断、异常、陷入机制（访管指令）
内核态&amp;mdash;&amp;gt;用户态：设置程序状态字PSW&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的&lt;/li&gt;
&lt;li&gt;处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。&lt;/li&gt;
&lt;li&gt;线程切换只能在内核态完成，如果当前用户处于用户态，则必然引起用户态与内核态的切换，线程的调度是在内核态运行的，而线程中的代码是在用户态运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;拷贝构造为什么参数必须传引用&#34;&gt;拷贝构造为什么参数必须传引用
&lt;/h3&gt;&lt;p&gt;原文链接：https://blog.csdn.net/xiao23597/article/details/131041511&lt;/p&gt;
&lt;h3 id=&#34;初始化参数列表有什么特点&#34;&gt;初始化参数列表有什么特点
&lt;/h3&gt;&lt;p&gt;只能在构造函数中使用&lt;br /&gt;
初始化参数列表的初始化顺序和成员变量的顺序一致&lt;br /&gt;
常量和引用在初始化参数列表中初始化&lt;br /&gt;
初始化参数列表可以调用成员对象的构造函数&lt;br /&gt;
当父类没有默认构造函数时，可以利用初始化参数列表调用父类的构造函数&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;什么时候调用拷贝构造&#34;&gt;什么时候调用拷贝构造
&lt;/h3&gt;&lt;p&gt;用已经存在的对象初始化新的对象的时候&lt;br /&gt;
当对象以值的形式作为函数的参数或返回值时&lt;br /&gt;
delete为什么先调用析构函数在调用free&lt;br /&gt;
因为先调用free的话，会导致内存泄漏，free直接释放对象的内存了，并没有释放对象所指向的内存&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;指针与引用&#34;&gt;指针与引用
&lt;/h3&gt;&lt;p&gt;原文链接：https://blog.csdn.net/weixin_45805339/article/details/128205810&lt;br /&gt;
引用与所引用的变量共用同一块内存空间&lt;/p&gt;
&lt;h3 id=&#34;函数指针&#34;&gt;函数指针
&lt;/h3&gt;&lt;p&gt;int（*p）（int,int）他可以接收add（int  a，int b） p=add 函数的名字就是地址
{ return a+b；}&lt;/p&gt;
&lt;h3 id=&#34;c空类大小为什么为1&#34;&gt;C++空类大小为什么为1
&lt;/h3&gt;&lt;p&gt;为了实现每个实例在内存中都有一个独一无二的地址，编译器往往会给一个空类隐含的加一个字节，这样空类在实例化后在内存得到了独一无二的地址，所以空类所占的内存大小是1个字节。&lt;/p&gt;
&lt;h3 id=&#34;strcpysprintymemcpy的区别&#34;&gt;strcpy，sprinty，memcpy的区别
&lt;/h3&gt;&lt;h4 id=&#34;1操作对象不同&#34;&gt;1.操作对象不同
&lt;/h4&gt;&lt;p&gt;strcpy的操作对象均为字符串
memcpy的两个对象是两个可以任意可操作的内存地址，不限于数据类型。&lt;/p&gt;
&lt;h4 id=&#34;效率不同&#34;&gt;效率不同
&lt;/h4&gt;&lt;p&gt;memcpy最快，strcpy慢&lt;/p&gt;
&lt;h4 id=&#34;实现功能不同&#34;&gt;实现功能不同
&lt;/h4&gt;&lt;p&gt;strcpy主要实现字符串变量间的拷贝
sprintf主要实现其他数据类型格式到字符串的转化
memcpy主要是内存块间的拷贝&lt;/p&gt;
&lt;h3 id=&#34;拷贝构造函数调用时机&#34;&gt;拷贝构造函数调用时机
&lt;/h3&gt;&lt;p&gt;用已经存在的对象去初始化新对象&lt;br /&gt;
作为函数参数和函数返回值&lt;br /&gt;
如何只在堆区申请对象&lt;br /&gt;
将析构函数私有化，编译器会检查析构函数是否可以被调用 栈区申请内存用alloca()&lt;br /&gt;
在栈区的话将new和delete重载为私有化&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;const&#34;&gt;const
&lt;/h3&gt;&lt;p&gt;const修饰变量时表示变量不可以修改，但是可以通过指针来修改&lt;br /&gt;
const修饰函数时，表示为常函数，常函数内的this指针是const * const this 所以常函数不能修改成员变量，也不能调用非常函数，这些是因为他们的this指针不匹配&lt;br /&gt;
const他作为函数的返回值时，可以防止被修改。&lt;br /&gt;
非常函数只能调用常函数，常函数可以调用非常函数也可以调用常函数&lt;br /&gt;
常函数和非常函数是重载关系&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;c类对象的初始化顺序&#34;&gt;C++类对象的初始化顺序
&lt;/h3&gt;&lt;p&gt;基类初始化，成员类对象初始化，自身构造函数初始化&lt;/p&gt;
&lt;h3 id=&#34;常量指针&#34;&gt;常量指针
&lt;/h3&gt;&lt;p&gt;const int &lt;em&gt;p 声明一个指向常量整数的指针，常量指针，指针p可以指向不同的内存地址，但所指向的整数不能通过p来修改。&lt;br /&gt;
const int a = 10;&lt;br /&gt;
const int b = 20;&lt;br /&gt;
const int&lt;/em&gt; p = &amp;amp;a;&lt;br /&gt;
// *p = 15; // 错误，不能通过指针修改所指向的常量整数&lt;br /&gt;
p = &amp;amp;b; // 合法，可以改变指针指向的地址&lt;br /&gt;
指针常量&lt;/p&gt;
&lt;h3 id=&#34;int--const-p&#34;&gt;int * const p
&lt;/h3&gt;&lt;p&gt;指针常量是指针本身是常量，即指针一旦初始化指向一个地址后，就不能再指向其他地址，但可以通过该指针修改所指向对象的值。&lt;br /&gt;
int c = 30;&lt;br /&gt;
int d = 40;&lt;br /&gt;
int * const p = &amp;amp;c;&lt;br /&gt;
*p = 35; // 合法，可以通过指针修改所指向的值&lt;br /&gt;
// p = &amp;amp;d; // 错误，不能改变指针&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;static&#34;&gt;Static
&lt;/h3&gt;&lt;p&gt;static修饰全局变量
如果想在头文件中定义全局变量，需要定义为静态全局变量，会防止重定义问题&lt;br /&gt;
static修饰局部变量
只作用在局部作用域，只会被初始化一次，不会随着函数的结束而被释放。&lt;br /&gt;
static修饰成员变量
静态成员变量在编译期间初始化&lt;br /&gt;
公有的静态成员变量可以通过类名：：和对象名直接访问
存放在静态区&lt;br /&gt;
静态成员变量在继承关系中父类和子类共享
必须在类外初始化，因为静态成员变量是属于类的，不是属于类的任何特定对象，这意味着无论创建了多少个类的实例，静态成员变量都只有一个副本，因此，他需要在类的外部初始化，以确保这个变量的唯一性。&lt;br /&gt;
static修饰成员函数时
静态成员函数没有this指针，因此静态成员函数不能访问非静态成员变量
也不能调用非静态成员函数。&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;抽象类为什么不能创建对象&#34;&gt;抽象类为什么不能创建对象
&lt;/h3&gt;&lt;p&gt;这是因为纯虚函数在虚函数表里存放的地址为0&lt;/p&gt;
&lt;h3 id=&#34;友元函数和友元类&#34;&gt;友元函数和友元类
&lt;/h3&gt;&lt;p&gt;通过友元，一个普通函数或者另一个类中的成员函数可以访问类中的私有成员和保护成员。友元正确的使用能提高程序的运行效率，但同时也破坏了类的封装性和数据的隐藏性。&lt;/p&gt;
&lt;h3 id=&#34;如何用代码判断大小端存储&#34;&gt;如何用代码判断大小端存储？
&lt;/h3&gt;&lt;p&gt;大端 字数据的高字节存储在低地址中&lt;br /&gt;
小端 字数据的低字节存储在低地址中&lt;br /&gt;
强制类型转换 int转为char 只会留下低地址的地方&lt;br /&gt;
巧用联合体&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;如何在类外访问私有成员&#34;&gt;如何在类外访问私有成员
&lt;/h3&gt;&lt;p&gt;通过公有方法访问，使用友元函数或友元类，使用指针强制转换reinterpret_cast &lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;面向过程语言&#34;&gt;面向过程语言
&lt;/h3&gt;&lt;p&gt;优点：性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗资源;比如单片机、嵌入式开发、 Linux/Unix等一般采用面向过程开发，性能是最重要的因素。&lt;br /&gt;
缺点：没有面向对象易维护、易复用、易扩展&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;面向对象语言&#34;&gt;面向对象语言
&lt;/h3&gt;&lt;p&gt;优点：易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统，使系统更加灵活、更加易于维护
在C++的面试中，面向对象编程（OOP）的概念和应用是经常被提及的话题。为了成功应对这类面试，你需要对OOP的基本原理、特性以及它们在C++中的实现方式有深入的理解。以下是一些常见的C++面向对象面试问题及其回答策略：
回答：面向对象编程是一种编程范式，它将现实世界中的事物抽象为对象，并使用类来定义这些对象的属性和行为。OOP的主要特性包括封装、继承和多态。通过OOP，我们可以创建模块化、可重用和可维护的代码。&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;封装：封装是隐藏对象的属性和实现细节，仅对外提供公共接口的过程。这有助于保护数据的完整性和安全性，同时也提高了代码的可维护性。&lt;/li&gt;
&lt;li&gt;继承：继承允许我们创建一个新的类（子类或派生类），它继承了一个或多个已存在的类（父类或基类）的属性和方法。这使得代码重用成为可能，并有助于建立类之间的层次结构。&lt;/li&gt;
&lt;li&gt;多态：多态是面向对象编程的一个重要特性，它允许我们使用父类类型的引用或指针来调用子类的方法。这使得我们可以在运行时动态地确定要调用的方法，从而实现更灵活和可扩展的代码。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;虚函数&#34;&gt;虚函数
&lt;/h3&gt;&lt;p&gt;多态
多态分静态多态和动态多态 &lt;br /&gt;
静态多态是在编译期间产生的多态 &lt;br /&gt;
而动态多态是在运行期间确定的多态 &lt;br /&gt;
静态多态包含： 函数重载 运算符重载 函数模板&lt;br /&gt;
动态多态包括： 父类指针或引用指向子类对象 并通过指针或引用调用重写函数&lt;br /&gt;
动态多态调用过程
首先会通过父类指针或引用访问到子类对象中的虚表指针，然后通过虚表指针找到虚函数表 通过虚函数表存放的虚函数地址去调用虚函数&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;虚函数表&#34;&gt;虚函数表
&lt;/h4&gt;&lt;p&gt;一个类只有一个 在编译阶段被构造 所有对象共享同一个虚函数表&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;虚函数表指针&#34;&gt;虚函数表指针
&lt;/h4&gt;&lt;p&gt;当类中存在虚函数时，编译器会给类增加一个指针类型的变量 放到虚函数表中 创建对象时就会创建一个虚函数表指针，在构造函数被赋值，&lt;br /&gt;
因为是在构造函数中被复赋值的 所以构造函数不可以为虚函数 &lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;析构函数可以是虚函数么&#34;&gt;析构函数可以是虚函数么？
&lt;/h4&gt;&lt;p&gt;可以 如果产生多态的话  一定要设置虚函数否则在编译时，由于编译器会把父类和子类的构造函数统一命名，那么此时析构函数为函数隐藏，如果父类中的析构函数为虚函数，那么将在子类的析构函数中去调用父类的析构函数，以此来避免内存泄漏&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;内联函数&#34;&gt;内联函数
&lt;/h3&gt;&lt;p&gt;提高效率 它可以将函数体直接嵌入到调用处，避免了常规函数 调用时的压栈，跳转等操作，如果程序的执行小于开辟栈帧等操作的时间有必要设置为内联函数&lt;br /&gt;
不能过于复杂 递归或代码太长&lt;br /&gt;
并非总是有效&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;堆和栈&#34;&gt;堆和栈
&lt;/h3&gt;&lt;p&gt;从内存角度上看 堆需要手动申请释放内存 在C++中一般用 new delete c中用 malloc free 栈区的对象不需要回收 由操作系统进行回收 栈的申请速度和释放比堆快的多 因为他是由操作系统来操作的 &lt;br /&gt;
栈的地址是高地址向低地址增长，堆的地址是低地址向高地址增长的&lt;br /&gt;
从数据结构上看 堆分为 最大堆和最小堆 &lt;br /&gt;
栈  先进后出&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;new-malloc&#34;&gt;new malloc
&lt;/h3&gt;&lt;p&gt;new是在堆区申请内存的 如果给类和结构体申请内存的话 会先调用malloc在调用构造函数
利用new创建的数据 返回数据对应的类型的指针&lt;br /&gt;
释放new申请的内存需要时候delete 如果是数组delete[]  当这个类的析构函数没有作用时
也可以使用free释放new申请的堆区空间&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;new和malloc的区别&#34;&gt;new和malloc的区别
&lt;/h3&gt;&lt;p&gt;new 会先执行malloc 在执行构造函数给成员变量赋值 &lt;br /&gt;
delete 先会执行析构函数 在执行free&lt;br /&gt;
new 返回值不需要强转 malloc 返回值需要强转&lt;br /&gt;
new 是运算符 malloc是c语言库函数&lt;br /&gt;
new 不需要传入具体的字节个数 malloc 需要传具体字节个数&lt;br /&gt;
new 会先执行malloc 在执行 构造函数给成员变量赋值 malloc 只分配堆区&lt;br /&gt;
new 申请失败会抛出异常 malloc会返回空&lt;br /&gt;
new可以重载因为是运算符&lt;/p&gt;
&lt;h3 id=&#34;final关键字&#34;&gt;final关键字
&lt;/h3&gt;&lt;p&gt;修饰虚函数，可以阻止子类重写父类这个函数。修饰类的话，表示不允许被继承&lt;/p&gt;
&lt;h3 id=&#34;移动语义&#34;&gt;移动语义
&lt;/h3&gt;&lt;p&gt;移动语义可以通过浅拷贝从一个对象转移到另一个对象这样就能减少不必要的临时对象的创建，拷贝以及销毁，大幅度提高性能，正常用对象初始化对象时会调用拷贝构造，如果这个对象占的堆区内存很大，就可以用右值引用进行性能优化。&lt;/p&gt;
&lt;h3 id=&#34;深拷贝浅拷贝&#34;&gt;深拷贝浅拷贝
&lt;/h3&gt;&lt;h4 id=&#34;浅拷贝shallow-copy&#34;&gt;浅拷贝（Shallow Copy）
&lt;/h4&gt;&lt;p&gt;是指在拷贝对象时，只是复制了对象中的成员变量的值的引用或指针。浅拷贝后的对象和原对象共享一份数据，修改一个对象可能会影响另一个对象。&lt;/p&gt;
&lt;h4 id=&#34;深拷贝deep-copy&#34;&gt;深拷贝（Deep Copy）
&lt;/h4&gt;&lt;p&gt;是指在拷贝对象时，会创建一个新的独立的对象，并复制原对象中的所有成员变量的值。深拷贝后的对象和原对象是完全独立的，修改一个对象不会影响另一个对象。&lt;/p&gt;
&lt;h3 id=&#34;auto&#34;&gt;auto
&lt;/h3&gt;&lt;h4 id=&#34;auto-1&#34;&gt;auto
&lt;/h4&gt;&lt;p&gt;让编译器通过初始值来进行类型推演，从而获得定义变量的类型，所以说auto定义的变量必须由初始值。&lt;/p&gt;
&lt;h4 id=&#34;decltype&#34;&gt;decltype
&lt;/h4&gt;&lt;p&gt;它的作用是选择并返回操作数的数据类型，在此过程中，编译器只是分析表达式并得到它的类型，去不进行实际的计算表达式的值。&lt;/p&gt;
&lt;h3 id=&#34;lambda&#34;&gt;Lambda
&lt;/h3&gt;&lt;p&gt;相当于一个内嵌的匿名函数，用于替换独立函数或者函数对象。&lt;br /&gt;
返回值，编译器会根据return语句自动推导返回值类型，但是需要主义的是lambda表达式不能通过列表初始化自动推导返回值类型，像vector，list这种。&lt;br /&gt;
sizeof捕获列表：如果lambda捕获了一些外部变量，它的大小将包含这些捕获变量的大小，每个捕获的变量都会在lambda的内部定义一个数据成员&lt;br /&gt;
状态：如果lambda没有捕获任何变量，则其大小通常是固定的，1字节。因为编译器需要给每个lambda表达式生成一个独特的类。&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;智能指针&#34;&gt;智能指针
&lt;/h3&gt;&lt;p&gt;智能指针的底层实现原理主要依赖于引用计数和RAII（‌资源获取即初始化）‌原则。&lt;br /&gt;
RALL：是C++语言的一种管理资源、避免资源泄漏的惯用法，利用栈对象自动销毁的特点来实现，这一概念最早由Bjarne Stroustrup提出。因此，我们可以通过构造函数获取资源，通过析构函数释放资源。‌&lt;br /&gt;
智能指针的主要目的是解决原始指针使用中的内存管理问题，‌如内存泄漏和悬挂指针等。‌智能指针的实现通常涉及到引用计数的机制，‌当智能指针指向的对象不再被使用时，‌引用计数会减少，‌当引用计数达到零时，‌智能指针会自动释放所指向的对象，‌从而避免内存泄漏。‌此外，‌智能指针还可以提供对对象生命周期的更精细控制，‌例如在需要时延迟对象的销毁或共享对象的所有权等
头文件是&lt;memory&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;shared_ptr&#34;&gt;shared_ptr
&lt;/h4&gt;&lt;p&gt;使用引用计数的方式来管理内存。多个shared_ptr可以指向同一个对象，当最后一个shared_ptr被销毁时，对象才会被释放。适用于多个对象需要共享同一个资源的场景，比如在多个函数之间传递一个对象，并且需要保证在所有使用该对象的地方都不再需要时才释放资源。&lt;/p&gt;
&lt;h4 id=&#34;unique_ptr&#34;&gt;unique_ptr
&lt;/h4&gt;&lt;p&gt;直接防止拷贝的方式解决智能指针的拷贝问题，简单而又粗暴，防止智能指针对象拷贝，保证资源不会被多次释放。
可以通过move函数转移给其他的unique_ptr，
unique_ptr是独占式的智能指针，它保证在任何时刻只有一个unique_ptr指向一个对象，当unique_ptr被销毁时，它所指向的对象也会被自动释放。适用于需要独占资源的场景，比如在函数内部创建一个对象并返回给调用者时，可以使用unique_ptr来确保资源的正确释放。&lt;/p&gt;
&lt;h4 id=&#34;weak_ptr&#34;&gt;weak_ptr
&lt;/h4&gt;&lt;p&gt;expired() 它是来判断观测的资源是否被释放
lock 获取管理所监测资源的share_ptr对象
reset 置零 其他减一
std::weak_ptr是一种弱引用的智能指针，它不会增加对象的引用计数，主要用于解决std::shared_ptr可能出现的循环引用问题。当需要观察一个由std::shared_ptr管理的对象，但又不想影响对象的生命周期时，可以使用std::weak_ptr。&lt;br /&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Network</title>
        <link>https://L-Y-D-0129.github.io/p/network/</link>
        <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/p/network/</guid>
        <description>&lt;img src="https://L-Y-D-0129.github.io/p/network/14d5f80f66984e48a8701cf2b360728d.jpeg" alt="Featured image of post Network" /&gt;&lt;h1 id=&#34;tcp&#34;&gt;TCP
&lt;/h1&gt;&lt;h2 id=&#34;tcp连接&#34;&gt;TCP连接
&lt;/h2&gt;&lt;h3 id=&#34;什么是tcp&#34;&gt;什么是TCP？
&lt;/h3&gt;&lt;p&gt;TCP是面向连接的、可靠的、基于字节流的传输协议。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;面向连接：一定是1对1 才能连接，不能像UDP协议可以一台主机同时向多个主机发送消息，也就是一对多是无法做到的&lt;/li&gt;
&lt;li&gt;可靠的：无论网络链路中出现了什么样的变化，TCP都可以保证一个报文一定能够到达接收端。&lt;/li&gt;
&lt;li&gt;字节流：就是可以说当在传输层发消息的时候，一个消息可能会被分割成多个tcp报文进行转发给网络层，我们不能认为一个tcp报文就是一个消息，所以tcp是面向字节流的 （由于是面向字节流 ，就有可能会出现粘包的问题。）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;如何唯一确定tcp连接&#34;&gt;如何唯一确定TCP连接？
&lt;/h3&gt;&lt;p&gt;通过四元组就是（源地址、源端口、目标地址、目标端口）&lt;br /&gt;
源地址存在IP协议的头部中，作用是通过IP协议发送报文给对方主机&lt;br /&gt;
端口号存在TCP的头部中，作用是通过TCP协议应该把报文给那个端口&lt;br /&gt;
通过这四个组合可以确定唯一的TCP连接&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;tcp-和-udp-有什么区别-应用场景是什么&#34;&gt;TCP 和 UDP 有什么区别？ 应用场景是什么？
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;连接上的区别&lt;br /&gt;
tcp 是面向连接的，传输数据之前要建立连接。&lt;br /&gt;
udp是不需要连接，即刻传输数据&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;服务对象&lt;br /&gt;
tcp是一对一的两点服务&lt;br /&gt;
udp是支持一对一，一对多，多对多的&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;可靠性&lt;br /&gt;
tcp是可靠性交付，数据可以没有差错，不丢失，不重复，按时到达。&lt;br /&gt;
udp不是可靠的，不保证可靠交付数据。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;拥塞控制、流量控制&lt;br /&gt;
tcp有流量控制和拥塞控制机制，保证数据的传输安全&lt;br /&gt;
udp没有这些，即使网络非常拥堵，也不影响udp的传输效率&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;首部开销&lt;br /&gt;
tcp 的首部开销比较大 ，再首部没有选项字段时时20 字节，如果使用了，会变长。&lt;br /&gt;
udp 的首部开销时固定的，比价小，只有8 字节&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;传输方式&lt;br /&gt;
tcp是字节流传输，没有边界（有可能导致粘包问题） ，单保证顺序和可靠&lt;br /&gt;
udp是一个包一个包发送的，有边界，但是不可靠。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;分片不同&lt;br /&gt;
tcp的数据大小再超多MSS大小，就会在传输层分片，目标主机收到会在传输层进行组装tcp数据包，如果中途丢失了，只需要传输丢失的部分即可。
MSS = MTU - IP （首部）- TCP（首部） &lt;br /&gt;
udp的大小如果超过了MTU（1500字节）大小，就会再IP层分片，目标主机收到会再IP 层组装，再给传输层。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么要进行三次握手不是二次四次&#34;&gt;为什么要进行三次握手，不是二次、四次？
&lt;/h3&gt;&lt;p&gt;原因有 3 个&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3次握手可以防止历史连接的建立，导致初始化混乱（主要原因）&lt;/li&gt;
&lt;li&gt;同步双方初始序列号&lt;/li&gt;
&lt;li&gt;避免资源浪费&lt;br /&gt;
防止旧连接的建立导致初始化混乱
我们假设一个情景就是当客户端第一次发起连接的时候，网络阻塞，这个时候客户端没有收到连接请求，客户端重启之后再次发出请求，这个时候旧的请求连接旧会比新的连接先到达，服务器进行回复，如果是两次握手在服务器接收到消息的时候，就已经建立了连接，这个时候服务器回复确认号以及序列号，但是客户端发现这不是我要接收到的序列号，就会发起RST报文，让服务器释放连接，造成了资源浪费，如果是三次握手就不会有这样的情况，因为不会再第一次握手就建立连接。&lt;br /&gt;
同步双方的序列号
TCP协议的通信双方，都必须维护一个序列号，序列号是可靠传输的一个关键因素。
它的作用：接收方可以根据序列号取出重复的数据， 可以根据序号接收，可以表示发送出去的数据包那些被接收了，通过ACK报文中的序列号来知道。
二两次握手只能确认一方的序列号。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tcp-为什么每次建立连接的序列号都要求不一样呢&#34;&gt;TCP 为什么每次建立连接的序列号都要求不一样呢？
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;1728008642807.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;
如果每次都一样，就大概率会遇到历史报文的序列号，恰好再对方的接收窗口内， 那么就回导致数据错乱，这样如果每次建立连接的序列号都不一样的化，就会很大程度上避免了这样的情况。&lt;br /&gt;
但是初始化序列号和 序列号 并不是无线递增的，就会发生回绕的情况， 这就代表这不能完全根据序列号来判断新老数据，为了解决这个问题 ，TCP使用了时间戳， tcp_timestamps ， 他有两个好处，一个就是便于RTT【包的往返时间】的计算，另一个就是防止序列号回绕的问题。&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;既然ip层会分片为什么tcp层还需要mss呢&#34;&gt;既然IP层会分片，为什么TCP层还需要MSS呢？
&lt;/h3&gt;&lt;p&gt;如果将TCP的整个报文，交给IP层来进行分片，有一个隐患就是当一个IP分片丢失，整个报文的所有分片都要重新上传，因为IP层没有超时重传机制，当有一个分片丢失，接收方就无法再IP层组装一个完整的TCP报文，也就无法发送确认接收的ACK，发送方一直无法接收到接收方的ACK确认，那么发送端就会触发TCP超时重传机制，再次组装重新交给IP层进行发送。这样的效率是不高的，因为数据包当大于MSS就会进行分片，那么也一定小于MTU，也就不需要IP层进行分片了。&lt;/p&gt;
&lt;h3 id=&#34;tcp和udp可以使用同一个端口么&#34;&gt;TCP和UDP可以使用同一个端口么？
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;多个TCP服务进程可以同时绑定同一个端口么？&lt;/li&gt;
&lt;li&gt;重启TCP服务进程时，为什么会出现“Address in use” 的报错信息？ 又该怎么避免面？&lt;/li&gt;
&lt;li&gt;客户端的端口可以重复使用吗？&lt;/li&gt;
&lt;li&gt;客户端TCP来凝结TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立连接么？ &lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以的，再数据链路层，通过mac地址来寻找局域网中的主机，再网络层中，通过IP地址来寻找网络中相连的主机和路由器。 再传输层中，通过端口号进行寻址，来识别同意计算机中的不同应用程序。 传输层中的两个协议TCP 和 UDP 再内核中式两个完全独立的模块。再IP包头部的协议号字段就能知道是哪个协议，并把它们发给对应的模块进行处理，最后再根据端口号确定送给那个程序。&lt;/p&gt;
&lt;h3 id=&#34;初始序列号isn是如何产生的&#34;&gt;初始序列号ISN是如何产生的？
&lt;/h3&gt;&lt;p&gt;初始 ISN 时基于时钟的， 每4微秒 +1 ，转一圈要4.55 个小时
RFC793 提出了初始化学列号ISN随机生成算法 ： ISN = M + F（四元组）&lt;br /&gt;
M 时一个计时器，每隔 4 微秒+1 &lt;br /&gt;
F 是一个Hash 算法， 根据四元组生成一个随机值，保证Hash算法不能被外部轻易推出。&lt;br /&gt;
而其，随机数是基于始终计时器进行递增的，随意基本不会出现相同的初始化序列号。&lt;/p&gt;
&lt;h3 id=&#34;第一次握手丢失会发生什么&#34;&gt;第一次握手丢失会发生什么？
&lt;/h3&gt;&lt;p&gt;客户端想和服务器建立TCP连接，会发送SYN 请求和一个初始化序列号， 如果第一个包丢失，倒置一直没收到服务器的SYN-ACK（第二次握手），就会触发【超时重传】 机制， 重传 SYN报文，而其重传的SYN的序列号都是一样的。 &lt;br /&gt;
不同版本的操作系统有不同的超时重传机制， 有点是1 秒 ， 有的是 3 秒，具体时间是内核来控制的。&lt;br /&gt;
在客户端没收到服务器的回应就会【超时重传】Linux 中有一个内核参数tcp_syn_retries来控制整个次数，&lt;br /&gt;
这个参数可以自定义， 默认值是5 。&lt;br /&gt;
一般的超时重传的时间是以2倍变化的，再第五次重传后再等待 32 秒，客户端再次发送请求，还是没有收到ACK确认，客户端就不会再发了，会断开TCP连接。 总耗时就是 1 +2 +4+8 +16 +32  = 63 大概1 分钟左右。&lt;/p&gt;
&lt;h3 id=&#34;第二次握手数据丢失会发生什么&#34;&gt;第二次握手数据丢失会发生什么？
&lt;/h3&gt;&lt;p&gt;客户端和服务器都会进行【超时重传】 因为客户端会认为自己没发过去，服务器也会觉得自己每发送过去。控制第二次握手的参数是 tcp_synack_retries 由内核决定。剩下的流程和i第一次是一样的。&lt;/p&gt;
&lt;h3 id=&#34;第三次握手对视会发生什么&#34;&gt;第三次握手对视会发生什么？
&lt;/h3&gt;&lt;p&gt;当服务端超时重传2次 SYN-ACK报文后，由于 tcp_synack_retries 为2，已达到最大重传次数，于是再等待一段时间(时间为上一次超时时间的2倍)，如果还是没能收到客户端的第三次握手(ACK 报文)，那么服务端就会断开连接。&lt;br /&gt;
因为第三次是客户端进行确认ACK报文， ACK报文不会重传！&lt;/p&gt;
&lt;h3 id=&#34;什么是syn攻击如何避免syn攻击&#34;&gt;什么是SYN攻击？如何避免SYN攻击？
&lt;/h3&gt;&lt;p&gt;就是攻击者再短时间内伪造不同的IP地址的SYN报文像服务器发送请求，服务器就会返回SYN+ACK，不会受到回应，久而久之就会导致服务器的半连接队列被占满，这样服务器不能为正常的用户服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;半连接队列（SYN队列）：就是当服务器收到SYN请求，将客户端的SYN请求加入到半连接队列中。&lt;/li&gt;
&lt;li&gt;全连接队列（Accept队列）：是当服务器与客户端通过3次握手之后，就会创建一个对象这个队列中。&lt;/li&gt;
&lt;li&gt;最后通过调用accpet() socket接口，从全连接队列中取出。&lt;br /&gt;
不管是，全连接还是半连接队列，都有最大长度限制，超过限制，默认情况都会丢弃报文导致，无法与其他建立连接。SYN攻击就是主共半连接队列，当TCP半连接队列满了，就无法与客户端建立连接了。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;避免SYN攻击的四种办法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调大netdev_max_backlog;&lt;/li&gt;
&lt;li&gt;增大TCP半连接队列&lt;/li&gt;
&lt;li&gt;开启tcp_syncookies;&lt;br&gt;
开启这个功能就是，当半连接队列满了之后，不丢弃报文，而是根据算法，计算除一个cookie值；
把这个值放在第二次握手的应答报文中，发送给客户端
当服务器接收到客户端的应答报文时，就会检查它的合法性，如果合法就会将对象放入Accept队列
最后再调用accpet() 接口 ， 从Accept队列中取出连接。
net.ipv4.tcp_syncookies参数有3 个值：&lt;br /&gt;
0 就是关闭该功能&lt;br /&gt;
1 就是仅当SYN半连接队列放不下时，再启用他&lt;br /&gt;
2 就是无条件开启功能&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;减少SYN+ACK重传次数&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tcp-连接断开&#34;&gt;TCP 连接断开
&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;1728008794957.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;
这就是TCP断开连接的过程，以及双方的状态
这里要注意的一点就是只有主动断开连接，才有TIME_WAIT状态&lt;/p&gt;
&lt;h3 id=&#34;为什么需要四次挥手&#34;&gt;为什么需要四次挥手？
&lt;/h3&gt;&lt;p&gt;因为是这样的，我们四次挥手的过程就是 ， 一方发出申请，发出申请的一方表示我想断开连接，我不会再发数据给你了，这个时候可以接收数据， 这个时候服务器回复一个确认，然后出现closed_wait 状态，这个时间，就是用来给服务器处理数据和发送消息的。等服务器数据处理完毕， 它才会发送FIN 报文来表示现在可以关闭连接，并且进入LAST_ACK状态，发起方收到来自服务器的FIN，返回ACK就会进入TIME_WAIT 状态。&lt;/p&gt;
&lt;h3 id=&#34;ack报文为什么不会重传&#34;&gt;ACK报文为什么不会重传？
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;ACK报文不消耗序列号
再TCP协议中，学列号用于表示发送的数据顺序，而ACK报文本身不携带数据，也不占序列号空间，所以不需要重传，可以通过后续发送方的响应进行判断是否ACK已经被成功接收。&lt;/li&gt;
&lt;li&gt;避免重复确认的混乱
就是ACK也要进行重传，那么如果有网络波动也就可能会导致一种情况，例如发送方的数据包1，2，3 ，正常情况下接收方收到数据包1 发送ACK确认序号为2 的报文。但如果这个ACK报文被重传了好多次，发送方会认为接收方一直在等待数据包 2，因为它连续收到了确认序号为 2 的 ACK，这就暗示着数据包 2 及后续的数据包可能没有被正确接收。，没有接收到数据2，3 从而进行不必要的传输。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;第一次挥手丢失会发生什么&#34;&gt;第一次挥手丢失会发生什么？
&lt;/h3&gt;&lt;p&gt;如果第一次挥手就发生数据丢失，客户端会触发【超时重传】机制，一般Linux中默认是 7 次不同的版本和内核版本可能有所不同， 时间也是2的倍数进行翻倍的，过了这个时间，客户端就会断开连接。&lt;/p&gt;
&lt;h3 id=&#34;第二次挥手丢失会发生什么&#34;&gt;第二次挥手丢失会发生什么？
&lt;/h3&gt;&lt;p&gt;首先发送断开请求的一方会进入FIN_WAIT_1状态，然后接收方的第二次挥手对视会导致，发送方无法确认他是否发送，它就会触发【超时重传】再进行发送FIN请求。接收方看到对方有发送了FIN请求就知道自己确认应答的消息没有发出，那么就会继续发送。但是如果还是丢失会根据一个限制超时重传的机制的数量来决定发送方会发出几次FIN请求。如果抵达了最大重传次数那么就会断开连接。
但是注意如果使用shutdown() 来进行关闭的话， 那么就要看shutdown()关闭的方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SHUT_RD：关闭接收通道，不能再从这个套接字接收数据&lt;/li&gt;
&lt;li&gt;SHUT_WR：关闭发送通道，不能通过这个套接字发送数据&lt;/li&gt;
&lt;li&gt;SHUT_RDWR: 同时关闭接收和发送通道&lt;br /&gt;
这里要注意的就是，如果shutdown只关闭读取的通道，而不关闭发送的通道，内核是不会发送FIN报文的，因为内核发送FIN报文的时候要看你是否有发送数据的能力，如果你有能力他是不会发送FIN报文的。&lt;br /&gt;
shutdown() 和 close() 的区别 ：
就是close() 有可能会导致数据的丢失，而shutdown() 可以更加灵活的控制关闭的过程，给数据缓冲的机会。 什么情况下close() 会导致数据丢失 以及为什么 shutdown（） 可以给缓冲区机会？&lt;br /&gt;
一个套接字可以执行一次shutdown() , 但只能被close() 多次&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;第三次挥手丢失会发生什么&#34;&gt;第三次挥手丢失会发生什么？
&lt;/h3&gt;&lt;p&gt;流程是这样的，当服务器接收到客户端的FIN 报文之后，内核会自动回复ACK报文，同时处于CLOSE_WAIT状态，故名思义，他就是为了等待程序自行调度close() 函数。&lt;br /&gt;
调用这个close() 函数， 内核就会发送FIN报文，同时进入LAST_ACK状态 也就是等待最后确认应答状态。&lt;br /&gt;
如果迟迟没有接收到客户端发送的确认应答，那么就会触发【超时重发】机制，同样这个重发次数仍然是通过tcp_orphan_retries 来控制的。&lt;br /&gt;
再进行第二次挥手的时候客户端就会进入到FIN_WAIT_2 状态默认是 60 s 如果一直没有接收到服务器的FIN报文客户端就会关闭。&lt;/p&gt;
&lt;h3 id=&#34;第四次挥手丢失会发生什么&#34;&gt;第四次挥手丢失会发生什么？
&lt;/h3&gt;&lt;p&gt;当客户端收到了服务器的第三次挥手的FIN报文客户端就会进入TIME_WAIT 状态 持续 2MSL ，此时服务器处于LAST_ACK 状态也就是等待最后确认的状态，但是第四次挥手丢失，就触发了服务器的【超时重传】机制，这样服务器就会再【超时重传】机制的限制内进行重发每一次重发都会导致，客户端重置2MSL定时器，直到服务器不在抵达的【超时重传】的限制后，客户端再等2MSL就关闭了，服务器会再次等待上次重传的时间的2倍 反正应该小于一分钟所以服务器会先行关闭。&lt;/p&gt;
&lt;h3 id=&#34;为什么tim_wiait-等待时间是2msl&#34;&gt;为什么TIM_WIAIT 等待时间是2MSL？
&lt;/h3&gt;&lt;p&gt;MSL 是报文的最大生存时间， 它是任何报文再网络上存在的最长时间， 超过这个时间报文就会被丢弃。 TCP 协议是基于 IP协议的 ， IP头中有一个字段是 TTL，是IP数据报可以经过的最大路由器数，每经过一个处理它的路由器他就会减 1 ， 当TTL=0 这个数据包将被丢弃，同时发送ICMP（互联网控制报文协议）报文通知源主机。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;MSL 和 TTL的区别：MSL的单位是时间， TTL的单位是经过路由器的跳数，所以MSL应该大于TTL消耗到0 的时间，以确保报文已经自然消亡。&lt;br /&gt;
TTL一般时间为64 ，Linux MSL的时间为30 秒 ，意味着Linux认为数据报文经过 64个路由器的时间不会超过 30 秒，如果超过了 ， 就认为报文已经消失再网络中了。&lt;br /&gt;
至于TIME_WAIT 的时间是 2MSL  = 60 s，是比较合理的，因为再网络中我发送给你，你处理后又会发送给我，这样一来一会2MSL刚好够了。&lt;/p&gt;
&lt;h3 id=&#34;为什么需要time_wait-状态&#34;&gt;为什么需要TIME_WAIT 状态？
&lt;/h3&gt;&lt;p&gt;主动发起关闭的一方才会，才会有TIME_WAIT 状态&lt;br /&gt;
需要TIME_WAIT 状态有连个原因：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为了保证被动关闭的一方，可以正确关闭
这个就是如果最后一次ACK确认丢失了，那么服务端就会触发【超时重传】，假设客户端没有TIME_WAIT 状态那么，进行第四次挥手之后就直接进入CLOSE 状态这个时候服务端如果向再向我发送FIN请求客户端就会放回RST 这样就导致服务器异常终止。这样的行为是不优雅的。&lt;/li&gt;
&lt;li&gt;防止历史连接中的数据，被后面相同的四元组的连接错误接收 &lt;br /&gt;
错误接收的情况，是seq 和 isn 都有是回绕的，这就意味着没有办法通过序列号来判断新老数据。
&lt;img src=&#34;1728008140414.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;
如上图：&lt;/li&gt;
&lt;li&gt;服务器关闭连接之前，发送的seq = 301 被网络延迟了&lt;/li&gt;
&lt;li&gt;接着，服务器以相同的四元组重新打开了连接， 这个时候之前被延迟的数据包恰好在客户端的接收窗口的范围内，那么就导致了数据错乱的问题。
所以TCP设计了TIME_WAIT 状态，以用来保证让两个方向的数据包都被丢弃，是的原来的数据包都自然消失，确保出现数据包一定是新的连接产生。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tcp重传机制滑动窗口流量控制拥塞控制&#34;&gt;TCP重传机制、滑动窗口、流量控制、拥塞控制
&lt;/h2&gt;&lt;p&gt;TCP数据包丢的情况，会用重传机制解决：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;超时重传&lt;/li&gt;
&lt;li&gt;快速重传&lt;/li&gt;
&lt;li&gt;SACK&lt;/li&gt;
&lt;li&gt;D-ACK&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;超时重传&#34;&gt;超时重传
&lt;/h3&gt;&lt;p&gt;再发送数据的时，设定一个定时器，当超过指定的时间后，没有搜到对方的ACK确认应答报文，就会重发数据。
有两种情况会导致超时重传：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据包丢失&lt;/li&gt;
&lt;li&gt;确认应答丢失
介绍两个词 一个是RTT ，一个是 RTO&lt;/li&gt;
&lt;li&gt;RTT 就是一个包的往返时间差值&lt;/li&gt;
&lt;li&gt;RTO 是由系列根据RTT 的公式进行计算的 &lt;br /&gt;
因为超时时间限制设置的太短和太长都不好，太短会倒是不必要的重传，是网络的负荷增大。太长呢又降低效率。
根据分析RTO因该比RTT略大一些就可以。&lt;br /&gt;
超时重传就一个问题：就是超时周期过程相对较长，次数是由内核里面的参数来决定的，等待时间都是 2 倍的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;快速重传&#34;&gt;快速重传
&lt;/h3&gt;&lt;p&gt;就是当客户端向服务器发送了数据，发送了5个包 ，有1，2，3，4，5 其中第二个丢失了， 但是还没有到超时的时间 ，这个时候服务器就会回复三个序列号为2 的ACK报文，这样服务器就会返回三个序列号为2 的ACK确认，在定时器之前，进行重传。&lt;br /&gt;
但是有一个问题就是，如果他有两个包丢失了他无法直接重传，两个因为他触发快速重传触发的事第一个丢失的包的ACK2，他就会传一个包，或者传多个 ， 一个会导致效率慢，多个有重复，增加传输压力。&lt;/p&gt;
&lt;h3 id=&#34;sack方法&#34;&gt;SACK方法
&lt;/h3&gt;&lt;p&gt;SACK就是选择重传： 就是当有数据丢失的时候可以通过TCP头部中加一个SACK的东西，它可以将已收到信息发送给发送方，这样发送方就可以只发送丢失的数据了。&lt;br  /&gt;
例如：使用条件：要双发都支持SACK，在Linux中 ， 可以通过 net.ipv4.tcp_sack 参数打开这个功能。
&lt;img src=&#34;1728010504987.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;duplicate-sack&#34;&gt;Duplicate SACK
&lt;/h3&gt;&lt;p&gt;Duplicate SACK  又叫D-SACK
D-SACK的好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以让【发送方】知道，是发出的包丢了，还是接收方回应的ACK包丢了&lt;/li&gt;
&lt;li&gt;可以知道是不是【发送方】的数据包被网络延迟了&lt;/li&gt;
&lt;li&gt;可以知道网络中是不是把【发送方】的数据包给复制了&lt;br /&gt;
在Linux中可以通过net.ipv4.tcp_dsack 开启/关闭这个功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;滑动窗口&#34;&gt;滑动窗口
&lt;/h3&gt;&lt;p&gt;滑动窗口的概念的引入，就是提高了效率，就好比你说一句我说一句， 你和我说完话，我有点事没回复你，你就不说话了么？ 对吧不现实，而且效率太慢了。&lt;br /&gt;
这就有了窗口这个概念，即使往返时间长，它也不会降低网络通信的效率。窗口的实现是操作系统开辟的一个缓存空间，发送方发送数据后，要将数据保存在缓存区中。如果定期到达并受到确认应答，此时数据就可以从缓存区清除了。
有了窗口，就有窗口大小，在窗口大小就是在范围内无需等待应答，可以继续发数据的最大值
窗口的大小由接收方决定：TCP头部有一个Window 字段， 就是窗口的大小，通过这个字段接收方，将字节还有多少缓存区可以接收数据告诉对方，于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。&lt;/p&gt;
&lt;h3 id=&#34;流量控制&#34;&gt;流量控制
&lt;/h3&gt;&lt;p&gt;其实就是通过控制窗口的大小来，控制流量，但是有可能导致窗口关闭，窗口关闭就又潜在的危险，就是当窗口关闭了，当接收方处理完数据，窗口增大的时候，想在发送ACK确认的话，如果这次ACK确认丢失了，就有可能导致，一种类似于死锁的现象，就是发送方等着接收方，增加窗口的大小，接收方等着发送方发送数据。&lt;br /&gt;
如何解决窗口关闭，导致的潜在死锁的问题呢？
使用名为窗口探测的机制，来解决这个死锁的情况， 就是当窗口关闭的时候， 发送方就会启动持续定时器，哪怕是接收方发送消息已经解决完了，窗口已经增大了，也可以等这个持续计时器超时后，发送方发送窗口探针报文，来解决死锁的局面。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果还没有增大窗口，就重启持续定时器。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;拥塞控制&#34;&gt;拥塞控制
&lt;/h3&gt;&lt;p&gt;因为当，在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。&lt;br /&gt;
拥塞窗口cwnd 是 min (swnd , rwnd)  &lt;br /&gt;
拥塞窗口cwnd 变化的规律 &lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只要网路中没有出现拥塞，cwnd就会增大&lt;/li&gt;
&lt;li&gt;相反网络中出现了拥塞，cwnd就会减少&lt;br /&gt;
只要【发送方】没有按时间，接收到ACK确认应答，也就是发生的【超时重传】， 就会被认为是网络拥塞。
拥塞控制主要是四个算法：&lt;/li&gt;
&lt;li&gt;慢启动&lt;/li&gt;
&lt;li&gt;拥塞避免&lt;/li&gt;
&lt;li&gt;拥塞发生&lt;/li&gt;
&lt;li&gt;快速恢复 &lt;br /&gt;
慢启动：当发送方每收到一个ACK ， 拥塞窗口 cwnd 的大小就会加1 。&lt;br /&gt;
慢启动算法，发包的个数是以指数增长的，慢启动门限，就是 ssthresh (slow start threshold) 状态变量。&lt;/li&gt;
&lt;li&gt;当cwnd &amp;lt; ssthresh 时， 使用慢启动算法&lt;/li&gt;
&lt;li&gt;当cwnd &amp;gt;= ssthresh 时，就会使用拥塞避免算法 &lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;拥塞避免算法：就是如果，当cwnd &amp;gt;= ssthresh 的时候 发包就不在是指数上涨的，变成了线性上涨，减小网络拥塞的概率，但是还是上涨趋势，网络慢慢进入了拥塞的状况了，于是就可能出现丢包现象，这时候就需要对丢失的数据进行重传，当触发了【重传机制】，也就是进入了【拥塞发生算法】&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;拥塞发生
重传机制是会【拥塞发生算法】是不同的&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;超时重传，调用的【拥塞发生算法】就会将ssthresh  = cwnd /2 ， cwnd =1 ，重新开始【慢启动算法】，这就相当于大幅度降低了传输的数量，可能会导致卡顿。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在Linux 中 使用 ss -nli 命令来查看 每个TCP 连接的cwnd的初始化的值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;快速重传，就是比较好的方式，当发生快速重传的时候，TCP认为这种情况不严重，因为大部分没有丢失，只丢失了一小部分，所以酌情处理，cwnd = cwnd/2 , ssthresh = cwnd。 进入快速恢复算法。&lt;br /&gt;
快速恢复
&lt;img src =&#34;1728011403134.jpg&#34; alt = &#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在快速恢复的过程中，首先 ssthresh= cwnd/2，然后 cwnd=ssthresh+3，表示网络可能出现了阻塞，所以需要减小 cwnd 以避免，加3代表快速重传时已经确认接收到了3个重复的数据包;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;随后继续重传丢失的数据包，如果再收到重复的 ACK，那么 cwnd 增加 1。加1代表每个收到的重复的 ACK 包，都已经离开了网络。这个过程的目的是尽快将丢失的数据包发给目标。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，恢复过程结束。&lt;br /&gt;
首先，快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变。&lt;br /&gt;
其次，过程2(cwnd逐渐加1)的存在是为了尽快将丢失的数据包发给目标，从而解决拥塞的根本问题(三次相同的 ACK 导致的快速重传)，所以这一过程中 cwnd 反而是逐渐增大的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tcp-一些经典的问题&#34;&gt;TCP 一些经典的问题
&lt;/h2&gt;&lt;h3 id=&#34;如何理解tcp是面向字节流的协议&#34;&gt;如何理解TCP是面向字节流的协议？
&lt;/h3&gt;&lt;p&gt;首先TCP是面向字节流， UDP是面向报文，因为操作系统对TCP和UDP协议的发送方的机制不同。&lt;br /&gt;
对于UDP就是当我们组装好UDP头部的时候，就会将报文交给网络层去处理，而操作系统不会对UDP进行拆分，所以发出去的UDP是一个完整的用户消息，每一个报文就是消息的边界，对于多个UDP操作系统是将UDP加入到队列中，当用户调用recvfrom() 的时候就从队列中取一个数据， 从内核拷贝给用户缓冲区。&lt;br /&gt;
对于TCP就是，操作系统会对TCP进行拆分，可能将一个TCP报文拆分成多个，在我们发送一条数据的时候，数据可能并没有被发送，只是从应用程序拷贝到内核中协议栈中，至于什么时候发送，要看发送窗口的大小、拥塞窗口以及当前发送缓冲区的大小。我们不能认为一个用户消息，就是一个TCP报文，所以说TCP是面向字节流的。&lt;br /&gt;
正式因为面向字节流，就容易导致粘包问题，解决粘包问题的方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;固定长度  &amp;ndash; 不现实&lt;/li&gt;
&lt;li&gt;设置特殊字符用来充当边界 &amp;ndash; 但是消息中原本既有了这个字符就麻烦了&lt;/li&gt;
&lt;li&gt;自定义消息结构  &amp;mdash; 还是比较灵活现实的 &lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;什么是PAWS机制？
当tcp_timestamps 选项开启的时候，PAWS机制就会自动开启，它的作用是防止，TCP包中的序列号放生回绕。&lt;br /&gt;
PAWS就是为了避免这个问题的而产生的，在开启tcp_timesamps 的选项的时候， 一台机器发送所有的TCP包都会带上发送时的时间戳， PAWS要求双方一起维护最近收到数据包的时间戳， 没收到一个数据包就会读取数据包中的时间戳跟Recent TSval 的值坐比较， 如果发现数据包中的时间戳不是递增的，就代表这个数据包是过期的， 应该被丢弃；&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;已经建立tcp连接再次收到syn会发生什么情况&#34;&gt;已经建立TCP连接，再次收到SYN，会发生什么情况？
&lt;/h3&gt;&lt;p&gt;在这样的情况例如：客户端和服务器已经建立了连接，后来客户端宕机了，客户端向服务器再次发送SYN请求， 这个时候服务器收到了客户端的SYN报文，但是服务器不知道客户端发生了宕机的情况，那么服务器就会回复一个，携带正确序列号和确认号的ACK报文，这个ACK称为 Challenge ACK 。&lt;br /&gt;
接着客户端收到这个CHallenge ACK的报文，发现并不是自己所期望的第二次握手，那么就会回复RST，服务器收到之后就断开了连接。&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;如何关闭一个tcp连接&#34;&gt;如何关闭一个TCP连接？
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;可以直接杀死进程
是的，这个是最粗暴的方式，杀掉客户端进程和服务端进程影响的范围会有所不同&lt;br /&gt;
在客户端杀掉进程的话，就会发送 FIN 报文，来断开这个客户端进程与服务端建立的所有 TCP 连接这种方式影响范围只有这个客户端进程所建立的连接，而其他客户端或进程不会受影响。&lt;br /&gt;
而在服务端杀掉进程影响就大了，此时所有的 TCP 连接都会被关闭，服务端无法继续提供访问服务。&lt;br /&gt;
很显然，直接杀死进程是不可取的， 那么我们因该使用什么方式来杀死进程呢？&lt;br /&gt;
在Linux 中有一个交killcx的工具就是可以平滑的关闭TCP连接，他的实现方式就是，通过这个killcx 工具伪造相同的四元组，代替客户端向服务器器发送SYN 请求。也就是利用了已经建立连接的TCP，再次发送SYN请求，这个时候服务器就会回复 Challenge ACK 。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;骗取服务器回复Challenge ACK 的序列号，从中得到服务器的确认号， 伪造RST来断开连接。&lt;/li&gt;
&lt;li&gt;骗取服务器回复Challenge ACK 的序列号，从中得到序列号，伪造RST来断开连接。&lt;br /&gt;
&lt;img src = &#34;1728012817700.jpg&#34; alt = &#34;这是一张图片&#34;&gt;&lt;br /&gt;
处理killcx 工具可以做到关闭TCP，tcpkill也可以做到，但是tcpkill工具是属于被动获取序列号的，它获取序列号的方式是，在TCP 通信的时候，获取正确的序列号， 从而发送RST报文关闭。这就代表tcpkill非常不适合关闭不活跃的TCP连接。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;四次挥手中收到乱序的fin会如何处理&#34;&gt;四次挥手中收到乱序的FIN会如何处理？
&lt;/h3&gt;&lt;p&gt;当收到乱序的FIN ， 会将这个乱序的数据包放入【乱序队列】中，当数据到达之后，再去判断队列中是否有FIN报文，有就会调用tcp_fin() 使状态有FIN_WAIT2 &amp;mdash;》TIME_WAIT 状态
&lt;img src = &#34;1728012959501.jpg&#34; alt = &#34;这是一张图片&#34;&gt;&lt;br /&gt;
所以说当不会立刻进入TIME_WAIT 状态。&lt;/p&gt;
&lt;h3 id=&#34;在time_wait状态下的tcp连接在收到syn报文会发生什么&#34;&gt;在TIME_WAIT状态下的TCP连接，在收到SYN报文会发生什么？
&lt;/h3&gt;&lt;p&gt;首先是这样的要看是否合法？ &lt;br /&gt;
如何判断合法性呢？就是通过序列号和时间戳（开启timesample）时间戳机制后，如果双方都开启了时间戳报文：&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;判断收到的客户端SYN的【序列号】是否比上一次【服务器】期望收到的下一个序列号要大，并且SYN的【时间戳】也要比【服务器】最后一次收到的报文时间戳要大。&lt;/li&gt;
&lt;li&gt;相反有一个不满足就不是合法的SYN&lt;/li&gt;
&lt;li&gt;如果没有开启时间戳选项，那么单独通过判断序列号是否比上一次大 ， true 就 合法 false 就不合法。&lt;br /&gt;
如果使合法的SYN， 就进行进行三次握手的过程， 如果是不合法的那么就返回RST报文断开连接。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当我们处于TIME_WAIT状态的时候，收到RST 会断开连接么？&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果net.ipv4.tcp_rfc1337 参数为0 ， 则会提前结束TIME_WAIT 状态，释放连接。&lt;/li&gt;
&lt;li&gt;如果net.ipv4.tcp_rfc1337 参数为1 ， 则会丢弃RST报文。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tcp的保活机制&#34;&gt;TCP的保活机制
&lt;/h3&gt;&lt;p&gt;定义一个时间段，在这个时间段里面，如果没有任何关联的活动，TCP的保活机制就会开始作用，每个一个时间间隔，机会发送一个探测报文，该报文的数据非常少，如果连续几个探测报文都没有，得到回应，则就认为则这个TCP连接死亡了，系统内核将错误信息通知给上层应用程序。这个是可以修改的&lt;br /&gt;
net.ipv4.tcp_keepalive_time= 7200;  // 保活时间为7200秒 ， 也就是在2小时内没有任何相关活动，就会开启保活机制。&lt;br /&gt;
net.ipv4.tcp_keepalive_intvl= 75;    //每次检验的时间间隔是75 秒&lt;br /&gt;
net.ipv4.tcp_keepalive_probes= 9;    //表示检测9次没有响应，认为对方是不可以到达，从而中断本次连接&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;客户端在拔掉网线之后tcp连接是否发生变化&#34;&gt;客户端在拔掉网线之后TCP连接是否发生变化？
&lt;/h3&gt;&lt;p&gt;客户端拔掉网线后，并不会直接影响 TCP 连接状态。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输&lt;br /&gt;
有数据传输的情况:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此，双方的 TCP 连接都断开了&lt;br /&gt;
没有数据传输的情况:&lt;/li&gt;
&lt;li&gt;如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在&lt;/li&gt;
&lt;li&gt;如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCPkeepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;服务器没有listen客户端发起连接会发生什么&#34;&gt;服务器没有listen，客户端发起连接会发生什么？
&lt;/h3&gt;&lt;p&gt;当服务器只绑定了IP地址和端口号，而没有调用listen 的话， 然后客户端对服务器发起建立连接，服务器会返回RST报文，来解除连接&lt;br /&gt;
Linux内核处理收到TCP报文的入口函数是 tcp_v4_rcv ，在收到报文之后，会调用 _inet_lookup_skb函数查找TCP报文所属socket 。然后会查找监听套接字，根据目的地址和端口算出哈希值，然后再哈希表中找到对应监听改端口socket。没有找到那么就会直接返回RST报文，来断开连接。&lt;/p&gt;
&lt;h3 id=&#34;没有accept-能建立tcp连接么&#34;&gt;没有accept， 能建立TCP连接么？
&lt;/h3&gt;&lt;p&gt;可以建立，因为三次握手的过程是不需要accept()的参与也能够完成的，其实accpet（）的作用就是从全连接队列里面将sock取出来，而其还是再握手之后才会调用accept() 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全连接队列：底层是一个链表， 因为里面存储的是已经建立连接的一些已完成三次握手的连接信息，通过调用accept()，函数来取出进行进一步的处理，从而创建一个真正用于数据传输的 socket  。因为这样的特性所以只要从头取就行，这个过程就是O(1) 的 。&lt;/li&gt;
&lt;li&gt;半连接队列：底层是一个哈希表，因为再队列中储存的是一些未完成三次握手，建立连接的信息，当三次握手完成我们就要将相应的IP端口的连接取出，所以我们要使用查询效率快的那就是哈希表，时间复杂度就是O（1）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;全连接队列满了会怎么样&#34;&gt;全连接队列满了会怎么样？
&lt;/h3&gt;&lt;p&gt;分为两种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tcp_abort_on_overflow  =  1  会直接向客户端发送RST报文 。&lt;/li&gt;
&lt;li&gt;tcp_abort_on_overflow  =  0 的时候会将最后一次客户端发送的ACK丢弃。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tcp四次挥手可以变成三次么&#34;&gt;TCP四次挥手，可以变成三次么？
&lt;/h3&gt;&lt;p&gt;在一定情况下使可以的，本身这个四次挥手再第二次挥手后 ， 如果没有数据是可以将三次挥手变成四次挥手的 ，但是这建立再没有数据的前提下。如果四次挥手就变成三次的话，如果有数据要发送就不好处理了。&lt;/p&gt;
&lt;h3 id=&#34;什么情况下会发生三次挥手&#34;&gt;什么情况下会发生三次挥手？
&lt;/h3&gt;&lt;p&gt;当被动关闭的一方没有数据要发送并且【开启了TCP 延迟确认机制】 ， 那么第二次和第三次挥手就会关闭。这个延迟确认机制是默认打开的。&lt;br /&gt;
什么是确认延迟机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当有响应的数据要发送的时候， ACK会随着响应数据一起立刻发送给对方。&lt;/li&gt;
&lt;li&gt;当没有响应数据要发送时，ACK将会延迟一段时间，以等待是否有由响应的数据可以一起发送&lt;/li&gt;
&lt;li&gt;如果在延迟等待发送ACK期间，对方的第二个数据报文又到达了，那么就会立刻发送ACK&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;优雅关闭shutdown-和-暴力关闭close&#34;&gt;优雅关闭（shutdown） 和 暴力关闭（close）
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;close()  ， 同时关闭socket的发送和读取方向， 也就是socket 不在有发送和读取的能力，这个时候内核就会像对方发送FIN报文 ，进行四次挥手， 但是如果使多进程/线程的情况向，共享一个socket，这样你 调用了close() 只是将 socket的引用计数-1 ， 并不会导致socket 不可用， 内核也就不会发送FIN 报文，这样不影响其他进程的读写操作，知道引用计数变为0 ，才发送FIN报文。&lt;/li&gt;
&lt;li&gt;shutdown() ，可以指定socket以那种发生进行关闭，如果使关闭发送方向，那么socket就没有了发送能力，但是还有接收数据的能力，如果使多线程/进程，共享一个socket，shutdown也不会管引用计数，直接就导致socket不可以用了  ，然后发送FIN报文，别的进程也用不了。&lt;/li&gt;
&lt;li&gt;SHUT_RD：关闭接收通道，不能再从这个套接字接收数据&lt;/li&gt;
&lt;li&gt;SHUT_WR：关闭发送通道，不能通过这个套接字发送数据&lt;/li&gt;
&lt;li&gt;SHUT_RDWR: 同时关闭接收和发送通道&lt;br /&gt;
调用close() ，这个时候同时关闭了发送和读写能力，这个时候也会完成四次会后只不过都是由操作系统来帮助我们完成四次挥手的过程，但是这个时候如果服务器再第二次挥手和第三次挥手的过程中发送数据，这部分数据就丢失了。因为关闭了接收和发送通道。&lt;br /&gt;
调用shutdown()  ，需要注意的是虽然有多种方式去关闭通道但是如果保留了【发送通道】代表这个socket还拥有发送的能力，那么内核就不会发送FIN报文。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Linux</title>
        <link>https://L-Y-D-0129.github.io/p/linux/</link>
        <pubDate>Sat, 17 Dec 2022 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/p/linux/</guid>
        <description>&lt;img src="https://L-Y-D-0129.github.io/p/linux/210925002600MB-0-lp.jpg" alt="Featured image of post Linux" /&gt;</description>
        </item>
        <item>
        <title>Mysql</title>
        <link>https://L-Y-D-0129.github.io/p/mysql/</link>
        <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/p/mysql/</guid>
        <description>&lt;img src="https://L-Y-D-0129.github.io/p/mysql/5d199bc887724f9aa80e557d03cf7e30.webp" alt="Featured image of post Mysql" /&gt;&lt;h2 id=&#34;执行一个select语句都发生了什么&#34;&gt;执行一个select语句都发生了什么?
&lt;/h2&gt;&lt;h3 id=&#34;大概流程&#34;&gt;大概流程
&lt;/h3&gt;&lt;p&gt;一个语句的执行分为两层&lt;/p&gt;
&lt;p&gt;​	server层:建立连接,分析并执行sql具体有 连接器 查询缓存 解析器 预处理器 优化器 执行器&lt;/p&gt;
&lt;p&gt;​    存储引擎层:数据的存储和执行&lt;/p&gt;
&lt;p&gt;连接器：建立连接，管理连接，校验用户身份；&lt;/p&gt;
&lt;p&gt;查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。mysql8.0已删除该换块；&lt;/p&gt;
&lt;p&gt;解析器： 解析sql,通过解析器对sol查询语句进行词法分析，语法分析，然后构建语法树，方便后续模块读取表名，字 段，语句类型；&lt;/p&gt;
&lt;p&gt;执行sql:   执行sql共有三个阶段：&lt;/p&gt;
&lt;p&gt;​				预处理阶段：检查表或字段是否存在；将 select 水 中的 符号扩展为表上的所有列。&lt;/p&gt;
&lt;p&gt;​				优化阶段：基于查询成本的考虑，选择查询成本最小的执行计划；&lt;/p&gt;
&lt;p&gt;​				执行阶段：根据执行计划执行sql查询语句，从存储引擎读取记录，返回给客户端；&lt;/p&gt;
&lt;h4 id=&#34;连接器&#34;&gt;&lt;strong&gt;连接器:&lt;/strong&gt;
&lt;/h4&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;mysql&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ip&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;user&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;password&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;##   ip指的是你要连接的服务器所在ip
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##   user 指的是用户名,管理员角色为 root
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;##    -p 是密码
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;查看数据库的连接情况&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;## 数据库中输入
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;processlist&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;5c52844a-c987-4767-bed8-1107f112a61c.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;command(命令) 指的是用户当前命令状态 sleep指的是连接完就没有执行命令&lt;/p&gt;
&lt;p&gt;query 刚查询过  后面的time 是空闲时间 6号用户已经空闲了736秒&lt;/p&gt;
&lt;p&gt;空闲连接不会一直占用 mysql定义了最大空闲时间,由wait_timeout参数控制默认值是8小时&lt;/p&gt;
&lt;p&gt;超出了这个世界连接器就会自动将它断开.&lt;/p&gt;
&lt;p&gt;也可以自己断开连接&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;kill&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;connection&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;     &lt;span class=&#34;c1&#34;&gt;//x是id
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;连接限制  用 max_connections 关键字表示 默认的是151 超过这个值就拒绝接下来的连接请求&lt;/p&gt;
&lt;p&gt;并报错提示 too many connections&lt;/p&gt;
&lt;p&gt;mysql 也和http一样有长短连接的概念区别如下&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//短连接
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;连接&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql服务器&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;tcp三次握手&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;执行&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;断开&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tcp四次挥手&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;//长连接
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;连接&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mysql服务器&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;tcp三次握手&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;执行&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;执行&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sql&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;err&#34;&gt;断开&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tcp四次挥手&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;但是使用长连接可能会导致占用内存增多，因为MySQL在执行查询过程中临时使用内存管理连接对象，这些连接对象资源只有在连接断开的时候才会释放。如果长连接累计很多，将导致MySQL服务占用内存太大，有可能会被系统强制杀掉，这样就会发生MySQL服务器异常重启现象。&lt;/p&gt;
&lt;p&gt;怎样解决长连接占用内存的问题呢？&lt;/p&gt;
&lt;p&gt;1.定期断开长连接&lt;/p&gt;
&lt;p&gt;2.客户端主动断开连接   客户端在执行完了一个很大的操作后在代码里调用 mysql_reset_connection函数来重置链接，达到释放内存的效果，将链接状态恢复到刚刚创建完成时的状态。&lt;/p&gt;
&lt;h4 id=&#34;查询缓存&#34;&gt;查询缓存
&lt;/h4&gt;&lt;p&gt;查询缓存就是 接受的一条指令之后先去查询缓存看一下,如果有就直接返回,它保存的形式是key -value  key是语句 value 是结果&lt;/p&gt;
&lt;p&gt;如果查询缓存没有就去数据库查一下返回并把这个语句和结果存key -value&lt;/p&gt;
&lt;p&gt;但是查询缓存命中率太低了,只要表一修改所有的查询缓存就会被清理掉&lt;/p&gt;
&lt;p&gt;有点鸡肋所以8.0之后就直接删除了&lt;/p&gt;
&lt;h4 id=&#34;解析器&#34;&gt;解析器
&lt;/h4&gt;&lt;p&gt;解析器只负责检查语法和构建语法树&lt;/p&gt;
&lt;p&gt;预处理&lt;/p&gt;
&lt;p&gt;检查sql查询语句中的表或者字段是否存在（其他博主扒源码发现的）&lt;/p&gt;
&lt;p&gt;将select中的*扩展为表上的所有列&lt;/p&gt;
&lt;h4 id=&#34;优化器&#34;&gt;优化器
&lt;/h4&gt;&lt;p&gt;优化器主要负责将sql查询语句的执行方案确定下来，比如选择使用什么索引&lt;/p&gt;
&lt;p&gt;要想知道一条语句使用了什么索引只需要在语句前加上expain命令，结果里面的key字段就是使用了哪个索引&lt;/p&gt;
&lt;h4 id=&#34;执行器&#34;&gt;执行器
&lt;/h4&gt;&lt;p&gt;执行sql语句&lt;/p&gt;
&lt;blockquote&gt;
&lt;h2 id=&#34;一行数据是如何被存储的&#34;&gt;一行数据是如何被存储的
&lt;/h2&gt;&lt;/blockquote&gt;
&lt;p&gt;mysql的数据存放在哪个文件？&lt;/p&gt;
&lt;p&gt;使用命令&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-mysql&#34; data-lang=&#34;mysql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;show&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;variables&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;like&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;datadir&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;一般是创建数据库就在/var/lib/mysql/ 里创建一个文件夹名字是数据库名&lt;/p&gt;
&lt;p&gt;假如说你有创建了一个表  table1 那么立里面就有三个文件&lt;/p&gt;
&lt;p&gt;db.opt 放当前数据库的默认字符集和字符校验规则&lt;/p&gt;
&lt;p&gt;table1.frm 放表结构信息&lt;/p&gt;
&lt;p&gt;table1.ibd 放表数据也被称为独占表空间文件&lt;/p&gt;
&lt;p&gt;表空间文件的结构是怎么样的?&lt;/p&gt;
&lt;p&gt;表空间由段(segment) 区(extent) 页 (page)行 (row)组成&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;表空间结构.drawio.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;1行(row)&lt;/p&gt;
&lt;p&gt;数据库表中的数据都是按行存放的&lt;/p&gt;
&lt;p&gt;2页(page)&lt;/p&gt;
&lt;p&gt;数据库读取数据一次io操作是页为单位,一次最少读取一页 16kb&lt;/p&gt;
&lt;p&gt;数据表中的行记录是用数据页来管理的&lt;/p&gt;
&lt;p&gt;3区(extent)&lt;/p&gt;
&lt;p&gt;innodb不是b+树存储数据  每一层都是通过双向链表连接的,如果按照页来分配存储空间那么可能相邻两页物理位置离得很远,查询的时会产生大量随机i/o&lt;/p&gt;
&lt;p&gt;所以如果存储大量数据的时候,按照区来分配存储空间 每个区1mb,对于16kb一页的话连续64个页划分为一个区,这样相邻页直接物理地址也是连着的就能使用顺序i/o了&lt;/p&gt;
&lt;p&gt;4段(segment)&lt;/p&gt;
&lt;p&gt;表是由各个段组成的,段是由多个区组成的 ,段分为&lt;/p&gt;
&lt;p&gt;索引段:存放B+树的非叶子节点区的集合&lt;/p&gt;
&lt;p&gt;数据段:存放B+树叶子节点区的集合&lt;/p&gt;
&lt;p&gt;回滚段:存放的是回滚数据区的集合,mvcc多版本并发控制就是利用了回滚段实现了多版本并发控制&lt;/p&gt;
&lt;p&gt;InnoDB行格式有哪些？&lt;/p&gt;
&lt;p&gt;InnoDB提供了四种行格式，分别是Redundant ，Compact，Dynamic和Compressed行格式。&lt;/p&gt;
&lt;p&gt;5.1会默认使用compact5，7之后默认使用Dynamic&lt;/p&gt;
&lt;h3 id=&#34;compact行格式长什么样子&#34;&gt;compact行格式长什么样子？
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;COMPACT.drawio.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;记录的额外信息&#34;&gt;记录的额外信息
&lt;/h3&gt;&lt;p&gt;包括：&lt;/p&gt;
&lt;h4 id=&#34;变长字段长度列表&#34;&gt;变长字段长度列表
&lt;/h4&gt;&lt;p&gt;主要是varchar text blob 类型的列所占的大小而且这个是逆序的&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;t_test.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;变长字段长度列表1.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;变长字段长度列表2.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;变长字段长度列表3.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;为什么是逆序呢？&lt;/p&gt;
&lt;p&gt;因为记录头里存的是指向下一个记录头信息的指针 这样通过指针到下一个记录头信息位置&lt;/p&gt;
&lt;p&gt;往左读就是记录头信息往右读就是真实数据&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;每个数据库表的行格式都有变长度字段字节数列表么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实变长字段的字节数列表不是必须的。&lt;/p&gt;
&lt;p&gt;当数据表没有变长度的时候，比如说全部都是int类型的字段，这时候表里的行格式就不会有变长字段长度列表了，因为没有必要，不如去掉以节省空间&lt;/p&gt;
&lt;p&gt;所有变长字段长度列表只出现在数据表有边长字段的时候&lt;/p&gt;
&lt;h4 id=&#34;null值列表&#34;&gt;null值列表
&lt;/h4&gt;&lt;p&gt;null值列表必须是整字节1字节8比特所有如果要表示至少表示所以如果要至少要有8列不满8列会自动补0，而且也是逆序表示&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;null值列表5.webp&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;注意只有可以为空的列才有这个NULL值列表&lt;/p&gt;
&lt;h4 id=&#34;记录头的信息&#34;&gt;记录头的信息
&lt;/h4&gt;&lt;p&gt;delete_mask:标识这条数据是否被删除 1表示删除&lt;/p&gt;
&lt;p&gt;next_record:下一条记录位置&lt;/p&gt;
&lt;p&gt;record_type:表示当前记录的类型,0表示普通记录1表示b+树非叶子节点记录,2表示最小记录,3表示最大记录&lt;/p&gt;
&lt;h4 id=&#34;记录的真实数据&#34;&gt;&lt;strong&gt;记录的真实数据&lt;/strong&gt;
&lt;/h4&gt;&lt;p&gt;里面除了真实数据还有三个隐藏的字段&lt;/p&gt;
&lt;/br&gt;
&lt;p&gt;row_id:如果不是主键或者唯一约束那么就会有这个row_id用来区分一样的数据 占6字节&lt;/p&gt;
&lt;p&gt;trx_id: 事务id,表示这个数据由哪个事务生成的, 占4个字节&lt;/p&gt;
&lt;p&gt;rool_pointer,  记录上一个版本的指针&lt;/p&gt;
&lt;p&gt;varchar(n)中n最大取值为多少?&lt;/p&gt;
&lt;h3 id=&#34;行溢出后mysql是怎么处理的&#34;&gt;行溢出后mysql是怎么处理的？
&lt;/h3&gt;&lt;p&gt;如果一个数据页存不了一条记录， 录，innodb存储引擎会自动将溢出的数据存放到溢出页中。
compact行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在溢出页中，然后真实数据处用20字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。
compressed和dynamic这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储20个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。&lt;/p&gt;
&lt;h3 id=&#34;mysql是怎么知道varchar实际占用数据的大小&#34;&gt;MySQL是怎么知道varchar（）实际占用数据的大小？
&lt;/h3&gt;&lt;p&gt;MySQL的compact行格式中会用变长字段长度列表存储变长字段实际占用的数据大小&lt;/p&gt;
&lt;h3 id=&#34;varcharn中n的最大取值为多少&#34;&gt;varchar（n）中n的最大取值为多少？
&lt;/h3&gt;&lt;p&gt;一行记录最大能存储65535字节 5字节的数据，但是这个是包含变长字段字节数列表所占用的字节数和null值列表所占用的字节数。所以，我们在算varchar(n)中n最大值时，需要减去这两个列表所占用的字节数。
如果一张表只有一个varchar(n)字段，且允许为null,字符集为ascii。varchar(n)中n最大取值为65532.
计算公式：65535-变长字段宇节数列表所占用的宇节数-null值列表所占用的字节数三65535-2-1三
65532.
如果有多个字段的话，要保证所有字段的长度+变长字段字节数列表所占用的字节数+null值列表所占用的字节数65535。&lt;/p&gt;
&lt;h2 id=&#34;索引&#34;&gt;索引
&lt;/h2&gt;&lt;p&gt;索引可以帮助存储引擎快速的查找数据的一种数据结构，形象点说索引就是数据的目录。Mysql 中使用的innoDB 存储引擎，采用最多索引是B+ tree索引。&lt;/br&gt;&lt;/p&gt;
&lt;h3 id=&#34;索引是什么&#34;&gt;索引是什么
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;索引就好比书的目录，用于快速查找。&lt;/li&gt;
&lt;li&gt;一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往存储在磁盘的文件中&lt;/li&gt;
&lt;li&gt;我们通常所说的索引，包括聚集索引、覆盖索引、组合索引、前缀索引、唯一索引等，没有特别说明，默认都是使用B+树结构组织的索引&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;索引的分类&#34;&gt;索引的分类：
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;按【数据结构】分类：B+tree索引、Hash索引、Full-text索引&lt;/li&gt;
&lt;li&gt;按【物理储存】分类：聚簇索引（主键索引）、二级索引&lt;/li&gt;
&lt;li&gt;按【字段特性】分类：主键索引、唯一索引、普通索引、前缀索引&lt;/li&gt;
&lt;li&gt;按【字段个数】分类：单列索引、联合索引&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;主键索引br&#34;&gt;主键索引&lt;/br&gt;
&lt;/h4&gt;&lt;p&gt;索引列中的值必须是唯一的，不允许有空值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;普通索引&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;唯一索引br&#34;&gt;唯一索引&lt;/br&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;索引列中的值必须是唯一的，但是允许为空值。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;全文索引br&#34;&gt;全文索引&lt;/br&gt;
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行lke模糊查询时效率比较低，这时可以创建全文索引。MyISAM和InnoDB中都可以使用全文索引。&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;空间索引&#34;&gt;空间索引
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;MySQL在5.7之后的版本支持了空间索引，而且支持OpenGIS几何数据模型。MySQL在空间索引这方面遵循OpenGIs几何数据模型规则。&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;前缀索引&#34;&gt;前缀索引
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定&lt;/br&gt;
在创建表的到时候，InnoDB 存储引擎会根据不同的场景选择不同的列作为索引：&lt;/li&gt;
&lt;li&gt;有主键，默认会使用主键作为聚簇索引的索引键(key)&lt;/li&gt;
&lt;li&gt;没有主键，就是选择第一个不包含NULL值的唯一列作为聚簇索引的索引(key)&lt;/li&gt;
&lt;li&gt;上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增的Id列作为聚簇索引的索引键（key）&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;聚簇索引&#34;&gt;聚簇索引
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;也就是主键索引的B+Tree的叶子节点存放的是实际的数据，所有完整的用户记录都存放再主键索引的B+ Tree的叶子节点里面&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;二级索引&#34;&gt;二级索引
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;也就是辅助索引，B+Tree的叶子节点存放主键值，而不是实际的数据。&lt;/br&gt;
所以，再查询的时候如果再二级索引中直接就可以查询到数据，那就不需要回表了，这个过程叫做【索引覆盖】，如果要查询的数据不在二级索引里面，那么就先查询二级索引，找到对应的叶子节点，取出主键，再去主键索引里面查询数据，这个过程就是回表&lt;/br&gt;
索引的优势和劣势：
优势：&lt;/li&gt;
&lt;li&gt;可以提高数据检索的效率，降低数据的IO成本，类似于书的目录&lt;/li&gt;
&lt;li&gt;通过索引对数据进行排序，降低数据排排序的成本，降低CPU 的消耗&lt;/li&gt;
&lt;li&gt;被索引的列会自动进行排序，包括【单列索引】 和【组合索引】，只是组合索引的排序要复杂一些&lt;/li&gt;
&lt;li&gt;如果按照索引列的顺序进行排序，对应order by 语句来说，效率就会提高很多&lt;/br&gt;
劣势：&lt;/li&gt;
&lt;li&gt;索引会占据磁盘空间&lt;/li&gt;
&lt;li&gt;索引虽然会提高查询数据的效率，但是也会降低更新表的效率，比如每次进行删除和插入的时候，MYSQL不仅要保存数据，还要保存或者更行对应的索引文件&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mysql为什么使用b树作为索引&#34;&gt;mysql为什么使用B+树作为索引？
&lt;/h3&gt;&lt;p&gt;因为mysql 的数据要持久化存储在硬盘中，因为硬盘是一个非常慢的存储设备，那么我们就要尽可能少的I/O操作次数内完成。&lt;/br&gt;
这一点我们首先想到的可能是二叉搜索树 可是二叉搜索树的存在极端的情况当每一次插入都是最大元素的时候它就会退化成链表查询的时间复杂度变成了O(n)  ，现在我们可以想到二叉平衡树对于二叉平衡树，毕竟是二叉的随着数据的增加，树高会增加，而树的高度就决定着I/O的次数，因为数据都储存在硬盘中，对每个几点的访问就是一次I/O那么所以树的高度越高，查询的效率就越低。&lt;/br&gt;
这个时候可以考虑不是二叉这样减少了树的高度，就可以提高树的效率，就引入了B树和B+ 树 。&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;B+树减少的IO次数 &lt;/br&gt;
B+ 树的非叶子节点只存储索引，因此在数据相同的情况下，相比既存数据又存储索引的B树，B+ 树会显得更加矮胖， 这样查询的I/O次数就比较少。&lt;/li&gt;
&lt;li&gt;B+树的查询效率更为稳定&lt;/br&gt;
B+树的查询效率就是固定为树高O(logn)，还是因为只有叶子节点存储数据。&lt;/li&gt;
&lt;li&gt;B+树的插入和删除的效率高&lt;/br&gt;
这是因为B+ 树又大量的冗余节点，这些冗余的索引让B+ 树在插入、删除的效率更高，比如删除节点的时候就不会想B树那样发生复杂的树的变化&lt;/li&gt;
&lt;li&gt;B+树更加适合范围查找&lt;/br&gt;
因为B+树的叶子节点使用链表连接起来了，并且是双端链表，有利于范围查找，而B树想实现范围查找，那么只能通过树的遍历来实现。&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最左匹配原则  ：
最左前缀匹配原则和联合索引的索引储存结构和检索方式有关。
在组合索引树中，最底层的叶子节点按照第一列a列从左到右递增排列，但是b列和c列是无序的，b列只有在a列值相等的情况下小范围内递增有序，而c列只能在a，b两列相等的情况下小范围内递增有序。
但是如果，查询的条件里面没有a 那么B+ 树就在不知道第一步如何查询了&lt;/p&gt;
&lt;h3 id=&#34;索引覆盖&#34;&gt;索引覆盖：
&lt;/h3&gt;&lt;p&gt;索引覆盖并不是索引的结构，是一种优化手段，当我们使用辅助索引的时候，这样通过辅助索引就可以拿到主键，如果我们还需要通过主键去获取其他数据那么就是【回表】，如果不需要了就可以直接返回这个叶子节点，这就是【索引覆盖】。
索引覆盖提高的效率，因为如果要进行回表就是增加了一倍的查询 覆盖可以3 次IO查询到，不覆盖就要6 次&lt;/br&gt;
避免回表
使用索引覆盖，举个例子:现有User表(id(PK),name(key),sex,address,hobby&amp;hellip;)&lt;/br&gt;
如果在一个场景下， select id,name,sex from user where name=&amp;lsquo;zhangsan&amp;rsquo;;这个语句在业务上频繁使用到，而user表的其他字段使用频率远低于它，在这种情况下，如果我们在建立 name 字段的索引的时候，不是使用单一索引，而是使用联合索引(name，sex)这样的话再执行这个查询语句是不是根据辅助索引查询到的结果就可以获取当前语句的完整数据。这样就可以有效地避免了回表再获取sex的数容
这里就是一个典型的使用覆盖索引的优化策略减少回表的情况。&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;联合索引&lt;/br&gt;
联合索引，在建立联合索引的时候， 尽量在多个单列索引上判断是否可以建立联合索引，联合索引不仅节省空间，还更容易出发索引覆盖，提高查询的效率。
建立联合索引的原则：
区分度  = 不同的数据/这里列种所有的数据    【0-1】
应该将使用最频繁的列、区分度高的列放在前面，频繁使用代表索引的利用率高，也可以在常需要作为查询返回的字段上增加到联合索引中，如果在联合索引上增加一个字段而使用到了覆盖索引，那我建议这种情况下使用联合系引。&lt;/p&gt;
&lt;h3 id=&#34;索引失效有那些&#34;&gt;索引失效有那些？
&lt;/h3&gt;&lt;p&gt;MyISAM 存储引擎的B+ 树索引叶子节点存储的是数据的物理地址也就是用户的指针&lt;/br&gt;
InnoDB 存储引擎，B+ 树索引的叶子节点保存数据本身，InnoDB存储引擎根据不同的索引类型，叶子几点存放的东西也不一样，对于聚簇索引放的是叶子节点存放的数据，如果是二级索引叶子节点存放的主键的值&lt;/br&gt;
索引失效的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当我们使用左或者左右模糊匹配的时候，也就是like %xx 或者like %xx% 这两种方式都会导致索引失效&lt;/li&gt;
&lt;li&gt;当我们查询条件中对索引列使用函数的时候，就会导致索引失效&lt;/li&gt;
&lt;li&gt;当我们查询条件中对索引列进行表达式计算的时候，也是无法使用索引的&lt;/li&gt;
&lt;li&gt;Mysql 再遇到字符串和数字比较的时候，会默认把字符串转换成数字，这导致查询条件和索引中存的原始数据不一致，就是索引列会发生隐式类型转换，又由于隐式类型转换是由CAST函数来实现的，就等于对索引列使用了函数，所以就会导致索引失效&lt;/li&gt;
&lt;li&gt;再联合索引中正确的使用最左匹配原则，也就是按照最左优先方式进行索引的匹配，否者就会导致索引失效&lt;/li&gt;
&lt;li&gt;再Where 子句中，如果使用or 来连接条件，如果存在非索引列那么就会导致索引失效&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;对索引使用左或者左右模糊匹配&#34;&gt;对索引使用左或者左右模糊匹配
&lt;/h4&gt;&lt;p&gt;当我们使用左或者左右模糊匹配的时代后，也就是like %xx 或者 like %xx% 这两种方式都会导致索引失效&lt;/br&gt;
因为B+ 树索引是按照【索引值】有序排列存储的，只能更具前缀进行比较，如果左边的模糊匹配了就无法进行比较了就导致索引失效了，这样就只能全表查询了&lt;/br&gt;&lt;/p&gt;
&lt;h4 id=&#34;对索引使用函数&#34;&gt;对索引使用函数
&lt;/h4&gt;&lt;p&gt;有时候我们会用一些Mysql 自带的函数来得到我们想要的结果，这样就要注意了，如果查询条件中队索引使用函数，就会导致索引失效，索引根据索引列的值进行有序储存，当我们使用了函数也就会导致索引列的值改变，我们就无法查询了，例如： 我们对 where year(date_column) = 2023 这里就是对存储日期的date_column 使用year 函数，索引是基于原始的date_column 的原始日期值构建的，而其查询条件是基于函数处理后的结果也就是年份值&lt;/br&gt;
在Mysql 8.0 中 对于索引使用函数，就有所不同了 ，如果我们经常执行一些对索引使用函数的情况我们可以建立函数索引， 用刚刚那个例子举例&lt;/br&gt;
create index idx_year on user_table(year(date_column))&lt;/br&gt;
这个需要开发人员自行创建&lt;/br&gt;&lt;/p&gt;
&lt;h4 id=&#34;对索引进行表达式计算&#34;&gt;对索引进行表达式计算
&lt;/h4&gt;&lt;p&gt;这个和对索引进行函数运算道理是一样的，因为索引里面存储的是原始数据，而不是id +2 之后的数据，比如我们查询的条件是where id +2 =10 这样就相当于查询条件变了 ，不能对索引就行表达式计算，可以where = 10 +2 这样是可以的&lt;/p&gt;
&lt;h4 id=&#34;对索引隐式类型转换&#34;&gt;对索引隐式类型转换
&lt;/h4&gt;&lt;p&gt;Mysql 的转换规则：例子：select &amp;ldquo;10&amp;rdquo; &amp;gt; 9&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mysql会自动将【字符串】 转换成数字，这个select &amp;ldquo;10 &amp;quot; &amp;gt; 9 就相当于select 10 &amp;gt; 9
所以在MySQL 中遇到字符串和数字进行比较的时候，会自动把字符串转换成数字，就是因为索引中存储的是原数据，现在我们的字符串变成了整数，这就好比 进行了 cast() 函数一样 从 字符串转换成int 所以我们的比较条件中的索引中不能存储字符串这样在进行查找的时候就会索引失效 ， 理解为就没有对索引就行修改就可以走索引，一旦对索引数据进行修改了就不能查询了，就要走全表了&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;联合索引最左匹配&#34;&gt;联合索引最左匹配
&lt;/h4&gt;&lt;p&gt;对于主键建立的索引叫做聚簇索引，对于普通字段建立的索引叫做二级索引，那么多个普通字段组合在一起创建的索引叫做【联合索引】，也叫组合索引&lt;/br&gt;
对于联合索引我们要注意创建时候的顺序。&lt;/br&gt;
联合索引要正确的使用需要遵循【最左匹配原则】，也就是最有优先的方式进行索引匹配&lt;/br&gt;
比如，船舰了一个索引（a , b, c ）的联合索引，它能匹配的联合索引就是：&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;where a= 1;&lt;/li&gt;
&lt;li&gt;where a=1 and b =2 ;&lt;/li&gt;
&lt;li&gt;where a=1 and b= 2 and c =3 ;
这个例子中不适用a 作为条件都是不满足最左匹配的 ，如果是a = 1 and c =2 呢？&lt;/br&gt;
传统的处理方式：&lt;/br&gt;
索引下推就是将5.5 中会先找到满足a=1 的数据将这些主键返回到server 层 ，server层会再对这些记录进行 c=2 的筛选，这就增加了不必要的数据传输和server层的处理负担&lt;/br&gt;
索引下推优化处理：&lt;/br&gt;
Mysql 5.6 中索引下推就是会同时判断a =1 和 c =2 这样的记录才会发送给server 这样就减少了传输量，提高了效率，尤其是处理大量数据时的效果更为明显&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;where-子句中的-or&#34;&gt;WHERE 子句中的 OR
&lt;/h4&gt;&lt;p&gt;再WHERE 子句中，如果OR 的前后如果有一个时非索引列，那么就会导致索引失效，因为，or 时满足一个都行，如果有一个不是索引列我们就要全表扫描&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;再Mysql中使用 explain + 语句来查看是否语句的状态是否用到索引&lt;/br&gt;&lt;/p&gt;
&lt;h2 id=&#34;事务&#34;&gt;事务
&lt;/h2&gt;&lt;h3 id=&#34;事务的定义&#34;&gt;事务的定义
&lt;/h3&gt;&lt;p&gt;Mysql中的事务主要那个用于处理操作量大、复杂度高的数据，比如说，在人员管理系统中，要删除一个人员，即需要删除人员的基本资料，又需要删除和该人员相关的信息，如信箱，文章等等。这样，这些数据库操作语句就构成一个事务!&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;事务是一种机制、一个操作序列，包含了一组数据库操作命令，并且把所有的命令作为一个整体一起向系统提交或者撤回请求，这一组数据是具有原子性的，要么都执行，要么都不执行。&lt;/li&gt;
&lt;li&gt;事务是一个不可以分割的逻辑单元，在数据库系统上执行并发操作，事务是最小的控制单元&lt;/li&gt;
&lt;li&gt;事务使用与多用户同时操作数据库系统的场景，如银行、保险公司及整卷交易系统等等。&lt;/li&gt;
&lt;li&gt;事务是通过事务的整体性保证数据的一致性&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;事务的特点acid&#34;&gt;事务的特点ACID
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;原子性 &lt;/br&gt;
意味着事务是一个完整操作，事务的元素是不可以分的，事务中的所有元素必须作为一个整体提交或者回滚，如果事务中的任何元素失败都代表整个事务都失败了&lt;/li&gt;
&lt;li&gt;一致性&lt;/br&gt;
在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏&lt;/br&gt;
当事务完成时，数据必须处于一致状态。&lt;/br&gt;
在事务开始前，数据库中存储的数据处于一致状态。&lt;/br&gt;
在正在进行的事务中，数据可能处于不一致的状态。&lt;/br&gt;
当事务成功完成时，数据必须再次回到已知的一致状态，&lt;/br&gt;
注意:只有当前三条性质都满足了，才能保证事务的一致性&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;隔离性&lt;/br&gt;
在并发的环境中，多个事务同时操作相同的数据时，每一个事务都有独立的完整事务空间&lt;/br&gt;
对数据进行修改的所有并发事务是彼此隔离的，表明事务必须是独立的，，它不应以任何方式依赖于或影响其他事务修改数据的事务可在另一个使用相同数据的事务开始之前访问这些数据，或者在另一个使用相同数据的事务结束之后访问这些数据。&lt;/br&gt;&lt;/li&gt;
&lt;li&gt;持久性&lt;/br&gt;
一旦事务提交完成之后，事务的效果会永远的保留在数据库中&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;事务的并发问题&#34;&gt;事务的并发问题
&lt;/h3&gt;&lt;h4 id=&#34;脏读读取到未提交的数据br&#34;&gt;脏读（读取到未提交的数据）&lt;/br&gt;
&lt;/h4&gt;&lt;p&gt;脏读就是在读取数据的时候读取到了，其他事务未进行提交的数据，没有进行提交就意味着这些数据最终可能不会更新到数据中。读取到了不一定最终存在的数据就是脏读&lt;/br&gt;
例：比如事务B执行过程中修改了数据X,在未提交前,事务A读取了X,而事务B却回滚了,这样事务A就形成了脏读。 也就是说,当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。&lt;/br&gt;
&lt;img src=&#34;1729338374279.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;读到已经提交不可重复读前后多次读取读取到不一样的数据br-&#34;&gt;读到已经提交、不可重复读（前后多次读取，读取到不一样的数据）&lt;br /&gt;
&lt;/h4&gt;&lt;p&gt;一个事务进行多次查询却返回了不同的数据。由于其他查询时系统中有其他事务对个数据进行了修改并在A事务结束前提交了，导致多次查询得到的数据是不一样的。&lt;br /&gt;
&lt;img src=&#34;1729338515484.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;&lt;/p&gt;
&lt;h4 id=&#34;可重复读幻读前后多次读取但是读取到的数据总量不一致&#34;&gt;可重复读、幻读（前后多次读取，但是读取到的数据总量不一致）
&lt;/h4&gt;&lt;p&gt;一个事务对一个表中的数据进行修改，这种修改设计到表中的全部数据行。同时，另一个事务也在修改这个表，这种修改是像表中插入/删除一条数据，那么操作前一个事务的用户会发现表中还有没有修改的数据行，就好像发生了幻觉一样&lt;br /&gt;
&lt;img src=&#34;1729338569990.jpg&#34; alt=&#34;这是一张图片&#34;&gt; &lt;br /&gt;
原因:因为mysal数据库读取数据时，是将数据放入缓存中，当事务B对数据库进行操作:例如删除所有数据且提交时，事务A同样能访问到数据，这就产生了幻读。&lt;br /&gt;
问题:解决了可重复读，但是会产生一种问题，错误的读取数据，对于其他事务添加的数据也将访问不到&lt;br /&gt;&lt;/p&gt;
&lt;h3 id=&#34;mysql的四种隔离级别&#34;&gt;Mysql的四种隔离级别
&lt;/h3&gt;&lt;h4 id=&#34;read-uncommitted读取尚未提交的数据&#34;&gt;read uncommitted（读取尚未提交的数据）
&lt;/h4&gt;&lt;p&gt;不解决脏读，允许脏读，其他事务只要修改了数据未提交也能读取），即使未提交，本事务也能看到修改后的数据值。也就是可能读取到其他会话中未提交事务修改的数据。&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安全性差，但性能最好（不使用）&lt;/li&gt;
&lt;li&gt;三种并发问题都没有解决&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;read-committed-提交读--读取已经提交的数据可以解决脏读问题&#34;&gt;read committed （提交读） ： 读取已经提交的数据，可以解决脏读问题
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;只能读取到提交后的数据&lt;/li&gt;
&lt;li&gt;Oralce等多数数据库默认的隔离级别就是提交都&lt;/li&gt;
&lt;li&gt;安全性较差 ，性能较好&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;repeatable-read可重复度解决脏读和不可重复读的问题&#34;&gt;repeatable read（可重复度）：解决脏读，和不可重复读的问题
&lt;/h4&gt;&lt;p&gt;通过在启动的时候创建一个一致性的试图，这个视图基于事务开始数据库的状态，在事务执行的过程中，它只能看到这个试图里面的数据，而不会看到其他事务未提交或者已经提交的数据&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL默认可重复读&lt;/li&gt;
&lt;li&gt;无论其他事务是否修改提交的数据，这个事务中看到的数据是始终不会受其他影响的&lt;/li&gt;
&lt;li&gt;安全性高，但是性能比较差&lt;/li&gt;
&lt;li&gt;会有幻读的问题  &lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;serializable--串行化-可以解决脏读不可重复度幻读&#34;&gt;serializable : 串行化： 可以解决脏读、不可重复度、幻读
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;相当于锁表&lt;/li&gt;
&lt;li&gt;完全串行化的读，每次都读都需要获得表级共享锁，读写互相都会阻塞&lt;/li&gt;
&lt;li&gt;安全性高、性能差&lt;br /&gt;
事务隔离级别的作用范围为两种&lt;/li&gt;
&lt;li&gt;全局级：对所有会话有效&lt;/li&gt;
&lt;li&gt;会话级：只对当前的会话有效&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mysql InnoDB 引擎的默认隔离界别虽然是【可重复读】，但是他很大程度上避免了幻读现象，解决的方案有两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;针对快照读，通过MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动看到的数据是一致的，即使中途其他事务插入了一条数据，是查询不出来的，所以就很好的避免了幻读问题&lt;/li&gt;
&lt;li&gt;针对当前读，通过next -ke lock （记录锁+ 间隙锁） 方式解决了幻读，因为当执行select &amp;hellip; for update 语句的时候 ， 会加上net-key lock ， 如果又其他事务再net-key lock锁范围内插入数据，那么这个插入语句会被阻塞的，无法插入成功，所以就很好的避免幻读问题&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;四种隔离界别是如何实现的&#34;&gt;四种隔离界别是如何实现的？
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;对于【读未提交】隔离级别来说，因为可以读取到未提交事务修改的数据，只要我们再读的时候读取最新的数据就好了&lt;/li&gt;
&lt;li&gt;对于【串行化】隔离级别来说，通过读写锁的方式来避免并行访问&lt;/li&gt;
&lt;li&gt;对于【提交读】和【可重复读】都是基于MVCC机制，InnoDB提供视图二者的区别就是提交读可以读取到其他事务提交后的数据，而可重复读是只能看到该事务开始时创建的视图。&lt;/br&gt;
执行【开始事务】命令，并不意味着启动事务，在MYSQL中有两种开始事务的命令，分别是：&lt;/li&gt;
&lt;li&gt;begin/start transaction 命令  从第一条select 语句开始&lt;/li&gt;
&lt;li&gt;start transaction with consisitent snapshot 命令 专门用于创建一个非常明确的一致性快照 立刻启动事务&lt;/br&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;read-view-在-mvcc里如何工作的&#34;&gt;Read View 在 MVCC里如何工作的？
&lt;/h3&gt;&lt;p&gt;基于MVCC多版本控制&lt;/br&gt;
Read View 有四个重要的字段：&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;m_ids: 指的时在创建Read View 时，当数据库中【活跃事务】的事务id 列表，注意是一个列表，其中活跃事务就是启动了，还没有提交的事务，就是运行中的事务&lt;/li&gt;
&lt;li&gt;min_trx_id ： 指在创建Read View 时，当前数据库中m_ids 列表中的id 最小的事务，也就是m_ids 的最小值&lt;/li&gt;
&lt;li&gt;max_trx_id : 这个并不是m_ids的最大值，而是创建Read View 时当前数据库中给下一个id 值，也就是全局事务中的最大值 +1&lt;/li&gt;
&lt;li&gt;creator_trx_id ： 指的时创建该Read View 的事务的事务id &lt;/br&gt;
&lt;img src = &#34;1729339809572.jpg&#34; alt=&#34;这是一张图片&#34;&gt;&lt;br /&gt;
当使用InnoDB 存储引擎的数据库表，它的聚簇索引记录中包含下面两个隐藏列：&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;trx_id ，当一个事务对聚簇索引记录进行改动的时候，就会把该事务的id 记录在 trx_id 隐藏列里面&lt;/li&gt;
&lt;li&gt;roll_pointer ，每次对某条聚簇索引记录进行改动的时候，都会把旧版本的记录写入到undo 日志中，然后这个隐藏列指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录
当一个事务去访问记录的时候，除了自己更新的记总是可见之外，还有这几种情况：&lt;/li&gt;
&lt;li&gt;如果记录的trx_id 指 小于 Read View中的min_trx_id 就代表当前查看记录的版本是其他事务已经提交过的，版本，在可重复读的隔离界别下，我们查看记录的版本是我们事务开始的时候拍摄的一致性快照里面的数据，说明其他这个版本的数据我们是可见的&lt;/li&gt;
&lt;li&gt;如果trx_id 在min_trx_id 和 max_trx_id 之间要进行判断这个trx_id 是否在m_ids 列表中&lt;br /&gt;
如果在就代表就代表是活跃事务的版本我们是不可见的&lt;br /&gt;
如果不在代表是其他事务已经提交过了的版本我们是可见的&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;如果trx_id 大于max_trx_id  代表整个版本的记录实在我们创建视图之后的事务生成的整个版本对于我们来说是不可见的  。 大部分这样的情况可以通过 roll_pointer 【回滚指针】去查看旧版本的数据&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>归档</title>
        <link>https://L-Y-D-0129.github.io/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>Links</title>
        <link>https://L-Y-D-0129.github.io/links/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/links/</guid>
        <description>&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;l&#34;&gt;部分内容出自：https://xiaolincoding.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>关于</title>
        <link>https://L-Y-D-0129.github.io/%E5%85%B3%E4%BA%8E/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/%E5%85%B3%E4%BA%8E/</guid>
        <description>&lt;p&gt;This is a test page for i18n support.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>搜索</title>
        <link>https://L-Y-D-0129.github.io/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://L-Y-D-0129.github.io/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
